{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is the code to pad the context and the query embedding matrices. ie. we first index the c0ntext and queries and then save them in the form of tensors as a pickeled file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import copy\n",
    "import os.path\n",
    "\n",
    "\n",
    "\n",
    "class Data_pad:\n",
    "\n",
    "    def __init__(self, data_path=\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\"):\n",
    "\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.out_prefix = \"train\"\n",
    "        \n",
    "\n",
    " \n",
    "   \n",
    "    def find_max_length(self, data):\n",
    "\n",
    "        \"\"\" Finds the maximum sequence length for data \n",
    "            Args:\n",
    "                data: The data from which sequences will be chosen\n",
    "               \n",
    "        \"\"\"\n",
    "        temp = 0\n",
    "        for i, _ in enumerate(data):\n",
    "            \n",
    "            if (len(data[i]) > temp):\n",
    "                temp = len(data[i])\n",
    "        \n",
    "        return temp\n",
    "    \n",
    "    def pickle_padded_sequence(self, prefix):\n",
    "        self.out_prefix = prefix\n",
    "       \n",
    "        with open(self.data_path + \"\\\\\" + prefix + \"_word_index.context_pkl.pkl\", \"rb\") as input_file:\n",
    "            context_word_index = pickle.load(input_file)\n",
    "        with open(self.data_path + \"\\\\\" + prefix + \"_word_index.context_pkl.pkl\", \"rb\") as input_file:\n",
    "            question_word_index = pickle.load(input_file)\n",
    "\n",
    "        self.pad_data(self.out_prefix,context_word_index)\n",
    "        self.pad_data(self.out_prefix,question_word_index)\n",
    "\n",
    "    def pad_data(self,prefix,data):\n",
    "\n",
    "        \"\"\" Pad the data to max_length given\n",
    "            Args: \n",
    "                data: Data that needs to be padded\n",
    "                max_length : The length to be achieved with padding\n",
    "            Returns:\n",
    "                padded_data : Each sequence is padded to make it of length\n",
    "                              max_length.\n",
    "        \"\"\"\n",
    "\n",
    "        self.out_prefix = prefix\n",
    "        padded_data = []\n",
    "        max_length =  self.find_max_length(data)\n",
    "\n",
    "        for lines in tqdm.tqdm(data):\n",
    "            if (len(lines) < max_length):\n",
    "                temp = np.lib.pad(lines, (0,max_length - len(lines)),\n",
    "                    'constant', constant_values=0)\n",
    "            else:\n",
    "                temp = lines[:max_length]\n",
    "            padded_data.append(temp)\n",
    "\n",
    "        padded_data = torch.from_numpy(np.array(padded_data)).int()\n",
    "        pickle.dump(padded_data, open(os.path.join(self.data_path, self.out_prefix + \"_word_index_padded.pkl\"), \"wb\")) \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_padding = Data_pad(data_path=\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 11873/11873 [00:00<00:00, 15819.63it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 11873/11873 [00:00<00:00, 16672.70it/s]\n"
     ]
    }
   ],
   "source": [
    "data_padding.pickle_padded_sequence(\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 130319/130319 [00:07<00:00, 16365.71it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 130319/130319 [00:08<00:00, 15883.40it/s]\n"
     ]
    }
   ],
   "source": [
    "data_padding.pickle_padded_sequence(\"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
