{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import logging\n",
    "import code\n",
    "import pickle\n",
    "import os\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Embedding\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "\n",
    "class DCN_Model(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, embedding_matrix, dropout_ratio, maxout_pool_size, max_number_of_iterations):\n",
    "        super(DCN_Model, self).__init__()\n",
    "\n",
    "        self.encoder = Word_Level_Encoder(hidden_dim, emb_matrix, dropout_ratio)\n",
    "        self.coattention_encoder = Coattention_Encoder(hidden_dim, maxout_pool_size, embedding_matrix, max_number_of_iterations, dropout_ratio)\n",
    "        self.decoder = Dynamic_Decoder(hidden_dim, maxout_pool_size, max_number_of_iterations, dropout_ratio)\n",
    "\n",
    "    def forward(self, context_word_indexes, context_word_mask, question_word_indexes, question_word_mask,span_tensor):\n",
    "        passage_representation = self.encoder.forward(context_word_indexes, context_word_mask)\n",
    "\n",
    "        question_representation = self.encoder.forward(question_word_indexes, question_word_mask)\n",
    "       \n",
    "\n",
    "        U_matrix = self.coattention_encoder.forward(question_representation, passage_representation,context_word_mask)\n",
    "\n",
    "#         print(span_tensor[0].size())\n",
    "\n",
    "        loss, index_start, index_end = self.decoder.forward(U_matrix, context_word_mask, span_tensor)\n",
    "\n",
    "        return loss, index_start, index_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_files_using_word_to_index(filename, _dict, max_words):\n",
    "\n",
    "    f = open(filename, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "    lines = f.readlines()\n",
    "    lines  = [l.lower() for l in lines]\n",
    "    encoded_lines = []\n",
    "    for l in lines:\n",
    "        tokens = l.split()\n",
    "        tokens = tokens[:max_words]\n",
    "        temp = []\n",
    "        for t in tokens:\n",
    "            if t in _dict:\n",
    "                temp.append(_dict[t])\n",
    "            else:\n",
    "                temp.append(1)\n",
    "\n",
    "        encoded_lines.append(temp[:])\n",
    "\n",
    "    return encoded_lines\n",
    "def find_max_length(data):\n",
    "\n",
    "    \"\"\" Finds the maximum sequence length for data\n",
    "        Args:\n",
    "            data: The data from which sequences will be chosen\n",
    "    \"\"\"\n",
    "    temp = 0\n",
    "    index = 0\n",
    "    for i, _ in enumerate(data):\n",
    "\n",
    "        if (len(data[i]) > temp):\n",
    "            temp = len(data[i])\n",
    "            index = i\n",
    "    return temp,index\n",
    "\n",
    "\n",
    "def pad_data(data):\n",
    "\n",
    "    \"\"\" Pad the data to max_length given\n",
    "        Args:\n",
    "            data: Data that needs to be padded\n",
    "            max_length : The length to be achieved with padding\n",
    "        Returns:\n",
    "            padded_data : Each sequence is padded to make it of length\n",
    "                          max_length.\n",
    "    \"\"\"\n",
    "    padded_data = []\n",
    "    max_length,index =  find_max_length(data)\n",
    "\n",
    "    for lines in data:\n",
    "        if (len(lines) < max_length):\n",
    "            temp = np.lib.pad(lines, (0,max_length - len(lines)),\n",
    "                'constant', constant_values=0)\n",
    "        else:\n",
    "            temp = lines[:max_length]\n",
    "        padded_data.append(temp)\n",
    "\n",
    "    padded_data = torch.from_numpy(np.array(padded_data)).type(torch.int64)\n",
    "\n",
    "    return padded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "data_dir = \"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\\"\n",
    "def get_pretrained_embedding(embedding_matrix):\n",
    "    embedding = nn.Embedding(*embedding_matrix.shape)\n",
    "    embedding.weight = nn.Parameter(torch.from_numpy(embedding_matrix).float())\n",
    "    embedding.weight.requires_grad = False\n",
    "    return embedding\n",
    "with open(data_dir + \"glove_word_embeddings.pkl\", \"rb\") as input_file:\n",
    "    embedding_matrix_words = pickle.load(input_file)\n",
    "    \n",
    "embedding = get_pretrained_embedding(embedding_matrix_words)\n",
    "\n",
    "with open(os.path.join(data_dir , \"dictionaries.pkl\"), \"rb\") as input_file:\n",
    "    dictionaries = pickle.load(input_file)\n",
    "word_to_index = dictionaries[\"word_to_index\"]\n",
    "\n",
    "\n",
    "context_path_train = os.path.join(data_dir, \"train.context\")\n",
    "context_tokens = open(context_path_train, \"r\", encoding=\"utf-8\").readlines()\n",
    "    \n",
    "\n",
    "context_word_index_old = index_files_using_word_to_index(context_path_train, word_to_index, 400)\n",
    "\n",
    "context_word_index = context_word_index_old[0:100]\n",
    "context_word_index = Variable(pad_data(context_word_index))\n",
    "context_word_index.requires_grad = False\n",
    "\n",
    "word_sequence_embeddings = embedding(context_word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1696,  0.0160, -0.0499,  0.1167,  0.0508, -0.0192,  0.1246,  0.0109,\n",
      "        -0.0703,  0.0379, -0.1481,  0.1130,  0.0287, -0.1677,  0.0618, -0.1429,\n",
      "        -0.1560,  0.1138, -0.0494,  0.1030, -0.1634, -0.0556, -0.1604,  0.0163,\n",
      "        -0.1033,  0.1691, -0.0814,  0.0414, -0.0799, -0.0599,  0.0862, -0.1673,\n",
      "         0.1429,  0.0342,  0.0771,  0.0640, -0.0052, -0.1170, -0.0212,  0.1423,\n",
      "         0.1076,  0.0930, -0.1570, -0.0211,  0.0964, -0.0314, -0.1519,  0.0555,\n",
      "         0.0997, -0.0666,  0.0491, -0.1069,  0.0014,  0.0559, -0.0516, -0.0303,\n",
      "        -0.0859,  0.0625,  0.0753,  0.0113, -0.0553,  0.1540, -0.1374,  0.1481,\n",
      "         0.1406, -0.0216, -0.0647, -0.1412,  0.0747,  0.0547,  0.1113, -0.0444,\n",
      "        -0.0984,  0.0201,  0.0704,  0.1566,  0.1341, -0.1072, -0.0030,  0.0875,\n",
      "         0.0781,  0.0268, -0.0842, -0.0226, -0.0542, -0.0460,  0.1508, -0.1167,\n",
      "         0.0659,  0.0403,  0.0854, -0.0103,  0.1290, -0.0669, -0.1134,  0.0838,\n",
      "         0.1443, -0.0277, -0.0063, -0.1098])\n",
      "tensor([   1,   32, 3887,    1,    1,    1,    1,    1,    1,  584,  242,  360,\n",
      "           1, 2192,    1,   14,    1,   63,  461,    1, 1840,    1,  184,  488,\n",
      "           4,  731,    1,  584,    4, 1057,    5, 1355,    1, 2235,    1,   50,\n",
      "         262,    5,  361,  837,    4, 3339, 3677,   10,    1,  192,    1,    4,\n",
      "        1931,    6, 2193,    5,    1,  343, 1254,   10,  549,  461,    3,  220,\n",
      "           1,  359,    1,  333,    1,  192,    1, 1775,   16,   27,  352,    1,\n",
      "        1932, 1234,    1,    1,  127,  118,   34,    3,    1,   61,    1,    1,\n",
      "         934,  453,    3,   59,   67,    1,   39, 2116,  426,    1,  168,    3,\n",
      "          32,    1,  395,   60,    1, 1413,    5,  198,    1,  588,    1,    1,\n",
      "          22,  325,   27,   10,    1,  294,  173,  342,    1,  525,  138,  353,\n",
      "         123,    4,  596,    1,  234,  500,  201,    1,  464,    1, 1000,    5,\n",
      "         198,    1,    4,    1, 2863, 1658,    1,    1,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0])\n",
      "<sos> beyoncé giselle knowles-carter ( /biːˈjɒnseɪ/ bee-yon-say ) ( born september 4 , 1981 ) is an american singer , songwriter , record producer and actress . born and raised in houston , texas , she performed in various singing and dancing competitions as a child , and rose to fame in the late 1990s as lead singer of r & b girl-group destiny 's child . managed by her father , mathew knowles , the group became one of the world 's best-selling girl groups of all time . their hiatus saw the release of beyoncé 's debut album , dangerously in love ( 2003 ) , which established her as a solo artist worldwide , earned five grammy awards and featured the billboard hot 100 number-one singles `` crazy in love '' and `` baby boy '' .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(word_sequence_embeddings[0][1])\n",
    "print(context_word_index[0])\n",
    "print(context_tokens[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-e1f39889e5ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0membedding_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0membedding_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## This references the loaded embeddings dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_words' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "file = open(data_dir + \"glove_embeddings100.txt\", \"r\", encoding=\"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split(' ')\n",
    "    word = values[0] ## The first entry is the word\n",
    "    vector = np.asarray(values[1:], dtype='float32') ## These are the vectors representing the embedding for the word\n",
    "    embeddings_index[word] = vector\n",
    "file.close()\n",
    "embedding_matrix = np.zeros((num_words, 100))\n",
    "for word, i in word_to_index.items():\n",
    "    embedding_vector = embeddings_index.get(word) ## This references the loaded embeddings dictionary\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(data_dir , \"train.context\"),\"r\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "glove_embeddings = os.path.join(data_dir, \"glove_embeddings100.txt\")\n",
    "\n",
    "glove_embeddings = open(glove_embeddings,'r', encoding = 'utf-8')\n",
    "word_embedding_size = 100\n",
    "temp_embeddings = []\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_to_index), 100))\n",
    "for word, i in word_to_index.items():\n",
    "    embedding_vector = embeddings_index.get(word) ## This references the loaded embeddings dictionary\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "for word in word_to_index:\n",
    "\n",
    "        if word in ['<pad>', '<sos>','<unk>']:\n",
    "            temp_vector = np.zeros((word_embedding_size))\n",
    "        elif word not in glove_embeddings:\n",
    "            temp_vector = np.random.uniform(-np.sqrt(3)/np.sqrt(word_embedding_size), np.sqrt(3)/np.sqrt(word_embedding_size), word_embedding_size)\n",
    "        else:\n",
    "            temp_vector = glove_embeddings[word]\n",
    "            \n",
    "#         print(str(word) + str(temp_vector))\n",
    "        temp_embeddings.append(temp_vector)\n",
    "\n",
    "temp_embeddings = np.asarray(temp_embeddings)\n",
    "temp_embeddings = temp_embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.11415606,  0.09369559,  0.13041882, ..., -0.17320384,\n",
       "         0.07250953,  0.08871087],\n",
       "       [ 0.10268117,  0.13954978,  0.05073194, ..., -0.0747427 ,\n",
       "         0.04370208, -0.13305794],\n",
       "       [ 0.12480463, -0.1261571 , -0.07739303, ...,  0.07390368,\n",
       "        -0.06525229, -0.1287655 ]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.68520999,  0.63674998,  0.14244001, ..., -0.0029878 ,\n",
       "        -0.55435997,  0.67944998],\n",
       "       [-0.56307   , -0.13433   ,  0.11604   , ...,  0.26135001,\n",
       "         0.28470999,  0.41460001],\n",
       "       [-0.7335    ,  0.29925001, -0.078124  , ...,  0.00693   ,\n",
       "         0.51097   ,  0.84179002]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<sos>': 1,\n",
       " '<unk>': 2,\n",
       " 'of': 3,\n",
       " 'and': 4,\n",
       " 'in': 5,\n",
       " 'to': 6,\n",
       " 'sos': 7,\n",
       " 'was': 8,\n",
       " 's': 9,\n",
       " 'as': 10,\n",
       " 'for': 11,\n",
       " 'on': 12,\n",
       " 'that': 13,\n",
       " 'is': 14,\n",
       " 'with': 15,\n",
       " 'by': 16,\n",
       " 'at': 17,\n",
       " 'his': 18,\n",
       " 'from': 19,\n",
       " 'what': 20,\n",
       " 'were': 21,\n",
       " 'which': 22,\n",
       " 'it': 23,\n",
       " 'he': 24,\n",
       " 'new': 25,\n",
       " 'are': 26,\n",
       " 'her': 27,\n",
       " 'who': 28,\n",
       " 'first': 29,\n",
       " 'city': 30,\n",
       " 'also': 31,\n",
       " 'beyoncé': 32,\n",
       " 'has': 33,\n",
       " 'one': 34,\n",
       " 'have': 35,\n",
       " 'york': 36,\n",
       " 'or': 37,\n",
       " 'had': 38,\n",
       " 'their': 39,\n",
       " 'be': 40,\n",
       " 'chopin': 41,\n",
       " 'this': 42,\n",
       " 'did': 43,\n",
       " 'season': 44,\n",
       " 'its': 45,\n",
       " 'after': 46,\n",
       " 'west': 47,\n",
       " 'not': 48,\n",
       " 'music': 49,\n",
       " 'she': 50,\n",
       " 'many': 51,\n",
       " 'most': 52,\n",
       " 'when': 53,\n",
       " 'been': 54,\n",
       " 'other': 55,\n",
       " 'million': 56,\n",
       " 'but': 57,\n",
       " 'they': 58,\n",
       " 'all': 59,\n",
       " 'album': 60,\n",
       " 'world': 61,\n",
       " 'two': 62,\n",
       " 'american': 63,\n",
       " 'chinese': 64,\n",
       " 'than': 65,\n",
       " 'during': 66,\n",
       " 'time': 67,\n",
       " 'torch': 68,\n",
       " 'some': 69,\n",
       " 'more': 70,\n",
       " 'year': 71,\n",
       " 'over': 72,\n",
       " 'show': 73,\n",
       " 'people': 74,\n",
       " 'china': 75,\n",
       " 'into': 76,\n",
       " 'how': 77,\n",
       " 'such': 78,\n",
       " 'us': 79,\n",
       " 'while': 80,\n",
       " 'where': 81,\n",
       " 'can': 82,\n",
       " 'dogs': 83,\n",
       " 'released': 84,\n",
       " 'about': 85,\n",
       " 'may': 86,\n",
       " 'only': 87,\n",
       " 'states': 88,\n",
       " 'including': 89,\n",
       " 'idol': 90,\n",
       " 'would': 91,\n",
       " 'i': 92,\n",
       " 'three': 93,\n",
       " 'united': 94,\n",
       " 'him': 95,\n",
       " 'film': 96,\n",
       " 'no': 97,\n",
       " 'ipod': 98,\n",
       " 'solar': 99,\n",
       " 'there': 100,\n",
       " 'relay': 101,\n",
       " 'song': 102,\n",
       " 'later': 103,\n",
       " 'number': 104,\n",
       " 'between': 105,\n",
       " 'used': 106,\n",
       " 'both': 107,\n",
       " 'dog': 108,\n",
       " 'best': 109,\n",
       " 'tibet': 110,\n",
       " 'years': 111,\n",
       " 'these': 112,\n",
       " 'second': 113,\n",
       " 'made': 114,\n",
       " 'single': 115,\n",
       " 'up': 116,\n",
       " 'school': 117,\n",
       " 'became': 118,\n",
       " 'through': 119,\n",
       " 'said': 120,\n",
       " 'however': 121,\n",
       " 'major': 122,\n",
       " 'awards': 123,\n",
       " '2008': 124,\n",
       " 'name': 125,\n",
       " 'out': 126,\n",
       " 'group': 127,\n",
       " 'since': 128,\n",
       " 'called': 129,\n",
       " 'them': 130,\n",
       " 'buddhism': 131,\n",
       " 'several': 132,\n",
       " 'four': 133,\n",
       " 'earthquake': 134,\n",
       " '2013': 135,\n",
       " 'being': 136,\n",
       " 'government': 137,\n",
       " 'five': 138,\n",
       " 'top': 139,\n",
       " 'well': 140,\n",
       " 'use': 141,\n",
       " 'state': 142,\n",
       " 'national': 143,\n",
       " 'olympic': 144,\n",
       " 'area': 145,\n",
       " 'apple': 146,\n",
       " 'according': 147,\n",
       " 'media': 148,\n",
       " 'public': 149,\n",
       " 'so': 150,\n",
       " 'early': 151,\n",
       " 'received': 152,\n",
       " 'ming': 153,\n",
       " 'french': 154,\n",
       " 'tibetan': 155,\n",
       " 'following': 156,\n",
       " 'part': 157,\n",
       " 'april': 158,\n",
       " 'under': 159,\n",
       " '2015': 160,\n",
       " 'each': 161,\n",
       " 'before': 162,\n",
       " 'then': 163,\n",
       " 'do': 164,\n",
       " 'known': 165,\n",
       " 'paris': 166,\n",
       " 'songs': 167,\n",
       " 'release': 168,\n",
       " 'link': 169,\n",
       " 'game': 170,\n",
       " 'lee': 171,\n",
       " 'life': 172,\n",
       " 'artist': 173,\n",
       " 'piano': 174,\n",
       " 'university': 175,\n",
       " 'become': 176,\n",
       " 'schools': 177,\n",
       " 'began': 178,\n",
       " 'performance': 179,\n",
       " 'video': 180,\n",
       " 'system': 181,\n",
       " '2010': 182,\n",
       " 'although': 183,\n",
       " 'record': 184,\n",
       " 'north': 185,\n",
       " 'water': 186,\n",
       " 'announced': 187,\n",
       " 'kanye': 188,\n",
       " 'any': 189,\n",
       " '1': 190,\n",
       " 'power': 191,\n",
       " 'child': 192,\n",
       " 'largest': 193,\n",
       " 'third': 194,\n",
       " '2014': 195,\n",
       " 'set': 196,\n",
       " 'does': 197,\n",
       " 'love': 198,\n",
       " 'buddha': 199,\n",
       " 'manhattan': 200,\n",
       " '100': 201,\n",
       " 'among': 202,\n",
       " 'held': 203,\n",
       " 'series': 204,\n",
       " 'won': 205,\n",
       " 'day': 206,\n",
       " 'contestants': 207,\n",
       " 'canadian': 208,\n",
       " 'same': 209,\n",
       " 'company': 210,\n",
       " 'found': 211,\n",
       " 'human': 212,\n",
       " 'sand': 213,\n",
       " 'buddhist': 214,\n",
       " 'named': 215,\n",
       " '2007': 216,\n",
       " 'could': 217,\n",
       " 'work': 218,\n",
       " 'family': 219,\n",
       " 'r': 220,\n",
       " 'march': 221,\n",
       " 'total': 222,\n",
       " 'spectre': 223,\n",
       " '2012': 224,\n",
       " 'energy': 225,\n",
       " '2009': 226,\n",
       " 'live': 227,\n",
       " '2011': 228,\n",
       " 'emperor': 229,\n",
       " 'due': 230,\n",
       " 'large': 231,\n",
       " '2006': 232,\n",
       " 'bond': 233,\n",
       " 'billboard': 234,\n",
       " 'police': 235,\n",
       " 'award': 236,\n",
       " 'around': 237,\n",
       " 'june': 238,\n",
       " 'century': 239,\n",
       " 'ten': 240,\n",
       " 'include': 241,\n",
       " 'september': 242,\n",
       " 'warsaw': 243,\n",
       " 'based': 244,\n",
       " 'like': 245,\n",
       " 'six': 246,\n",
       " 'country': 247,\n",
       " 'much': 248,\n",
       " 'high': 249,\n",
       " 'musical': 250,\n",
       " 'event': 251,\n",
       " 'population': 252,\n",
       " 'mother': 253,\n",
       " 'technology': 254,\n",
       " 'end': 255,\n",
       " 'will': 256,\n",
       " 'minister': 257,\n",
       " '2': 258,\n",
       " 'january': 259,\n",
       " 'wrote': 260,\n",
       " 'twilight': 261,\n",
       " 'performed': 262,\n",
       " 'november': 263,\n",
       " '10': 264,\n",
       " 'judges': 265,\n",
       " 'included': 266,\n",
       " 'relationship': 267,\n",
       " 'court': 268,\n",
       " 'rights': 269,\n",
       " 'february': 270,\n",
       " 'took': 271,\n",
       " 'artists': 272,\n",
       " 'protests': 273,\n",
       " 'line': 274,\n",
       " 'week': 275,\n",
       " 'list': 276,\n",
       " 'own': 277,\n",
       " 'along': 278,\n",
       " 'because': 279,\n",
       " 'international': 280,\n",
       " 'another': 281,\n",
       " 'education': 282,\n",
       " 'until': 283,\n",
       " 'death': 284,\n",
       " 'published': 285,\n",
       " 'version': 286,\n",
       " 'form': 287,\n",
       " 'route': 288,\n",
       " '20': 289,\n",
       " 'concert': 290,\n",
       " 'home': 291,\n",
       " 'island': 292,\n",
       " 'seasons': 293,\n",
       " 'solo': 294,\n",
       " 'throughout': 295,\n",
       " 'using': 296,\n",
       " '2005': 297,\n",
       " 'those': 298,\n",
       " 'female': 299,\n",
       " '11': 300,\n",
       " 'tour': 301,\n",
       " 'reported': 302,\n",
       " 'president': 303,\n",
       " 'students': 304,\n",
       " 'county': 305,\n",
       " 'book': 306,\n",
       " 'next': 307,\n",
       " 'beijing': 308,\n",
       " 'air': 309,\n",
       " 'children': 310,\n",
       " 'if': 311,\n",
       " 'gave': 312,\n",
       " 'against': 313,\n",
       " 'place': 314,\n",
       " 'park': 315,\n",
       " 'last': 316,\n",
       " 'america': 317,\n",
       " 'house': 318,\n",
       " 'back': 319,\n",
       " 'days': 320,\n",
       " 'forces': 321,\n",
       " 'production': 322,\n",
       " 'per': 323,\n",
       " 'square': 324,\n",
       " 'established': 325,\n",
       " 'black': 326,\n",
       " 'times': 327,\n",
       " 'within': 328,\n",
       " 'works': 329,\n",
       " 'age': 330,\n",
       " 'women': 331,\n",
       " 'writes': 332,\n",
       " 'destiny': 333,\n",
       " 'records': 334,\n",
       " '–': 335,\n",
       " '12': 336,\n",
       " 'english': 337,\n",
       " 'games': 338,\n",
       " 'led': 339,\n",
       " 'seven': 340,\n",
       " 'center': 341,\n",
       " 'worldwide': 342,\n",
       " 'late': 343,\n",
       " 'beyonce': 344,\n",
       " 'having': 345,\n",
       " 'support': 346,\n",
       " 'hong': 347,\n",
       " 'often': 348,\n",
       " 'previous': 349,\n",
       " 'you': 350,\n",
       " 'great': 351,\n",
       " 'father': 352,\n",
       " 'grammy': 353,\n",
       " 'october': 354,\n",
       " 'now': 355,\n",
       " 'still': 356,\n",
       " 'further': 357,\n",
       " 'south': 358,\n",
       " 'b': 359,\n",
       " '4': 360,\n",
       " 'various': 361,\n",
       " '15': 362,\n",
       " 'others': 363,\n",
       " 'without': 364,\n",
       " 'long': 365,\n",
       " 'composer': 366,\n",
       " '5': 367,\n",
       " 'television': 368,\n",
       " 'considered': 369,\n",
       " 'official': 370,\n",
       " 'history': 371,\n",
       " 'role': 372,\n",
       " 'july': 373,\n",
       " 'original': 374,\n",
       " 'average': 375,\n",
       " 'london': 376,\n",
       " 'play': 377,\n",
       " 'lama': 378,\n",
       " 'novel': 379,\n",
       " 'central': 380,\n",
       " 'flame': 381,\n",
       " 'sichuan': 382,\n",
       " 'prime': 383,\n",
       " 'sold': 384,\n",
       " 'dynasty': 385,\n",
       " 'republic': 386,\n",
       " 'making': 387,\n",
       " 'term': 388,\n",
       " 'wii': 389,\n",
       " 'sales': 390,\n",
       " 'fourth': 391,\n",
       " 'kong': 392,\n",
       " 'stated': 393,\n",
       " 'british': 394,\n",
       " 'debut': 395,\n",
       " 'even': 396,\n",
       " 'polish': 397,\n",
       " 'princess': 398,\n",
       " 'created': 399,\n",
       " 'take': 400,\n",
       " 'office': 401,\n",
       " 'style': 402,\n",
       " 'buildings': 403,\n",
       " 'note': 404,\n",
       " 'khan': 405,\n",
       " 'title': 406,\n",
       " 'very': 407,\n",
       " 'eight': 408,\n",
       " 'op': 409,\n",
       " 'studio': 410,\n",
       " 'white': 411,\n",
       " 'congo': 412,\n",
       " 'members': 413,\n",
       " 'played': 414,\n",
       " 'mahayana': 415,\n",
       " 'jay': 416,\n",
       " 'described': 417,\n",
       " 'kill': 418,\n",
       " 'performances': 419,\n",
       " 'order': 420,\n",
       " 'war': 421,\n",
       " 'systems': 422,\n",
       " 'left': 423,\n",
       " '3': 424,\n",
       " 'military': 425,\n",
       " 'saw': 426,\n",
       " 'never': 427,\n",
       " 'pop': 428,\n",
       " 'success': 429,\n",
       " 'example': 430,\n",
       " 'modern': 431,\n",
       " 'my': 432,\n",
       " 'returned': 433,\n",
       " 'areas': 434,\n",
       " 'albums': 435,\n",
       " 'development': 436,\n",
       " 'm': 437,\n",
       " 'region': 438,\n",
       " 'officials': 439,\n",
       " '30': 440,\n",
       " 'general': 441,\n",
       " 'health': 442,\n",
       " 'india': 443,\n",
       " 'z': 444,\n",
       " 'final': 445,\n",
       " 'developed': 446,\n",
       " 'though': 447,\n",
       " 'continued': 448,\n",
       " 'billion': 449,\n",
       " 'period': 450,\n",
       " 'km': 451,\n",
       " 'genome': 452,\n",
       " 'groups': 453,\n",
       " 'august': 454,\n",
       " 'different': 455,\n",
       " 'zelda': 456,\n",
       " 'december': 457,\n",
       " 'industry': 458,\n",
       " 'way': 459,\n",
       " 'small': 460,\n",
       " 'singer': 461,\n",
       " 'brooklyn': 462,\n",
       " 'suffering': 463,\n",
       " 'singles': 464,\n",
       " 'make': 465,\n",
       " 'river': 466,\n",
       " 'nine': 467,\n",
       " 'light': 468,\n",
       " 'fashion': 469,\n",
       " 'building': 470,\n",
       " 'instead': 471,\n",
       " 'college': 472,\n",
       " '24': 473,\n",
       " 'shows': 474,\n",
       " 'main': 475,\n",
       " 'himself': 476,\n",
       " 'mockingbird': 477,\n",
       " 'protesters': 478,\n",
       " 'right': 479,\n",
       " 'whose': 480,\n",
       " 'available': 481,\n",
       " 'less': 482,\n",
       " 'despite': 483,\n",
       " 'writing': 484,\n",
       " 'old': 485,\n",
       " 'study': 486,\n",
       " 'ipods': 487,\n",
       " 'producer': 488,\n",
       " 'cover': 489,\n",
       " 'web': 490,\n",
       " 'put': 491,\n",
       " 'result': 492,\n",
       " '7': 493,\n",
       " 'head': 494,\n",
       " 'service': 495,\n",
       " 'religious': 496,\n",
       " 'critics': 497,\n",
       " 'scout': 498,\n",
       " 'stage': 499,\n",
       " 'hot': 500,\n",
       " 'revealed': 501,\n",
       " 'written': 502,\n",
       " 'street': 503,\n",
       " 'capital': 504,\n",
       " 'woman': 505,\n",
       " 'winner': 506,\n",
       " 'every': 507,\n",
       " 'dalai': 508,\n",
       " '2004': 509,\n",
       " 'recording': 510,\n",
       " 'just': 511,\n",
       " 'nt': 512,\n",
       " 'introduced': 513,\n",
       " 'given': 514,\n",
       " 'star': 515,\n",
       " 'return': 516,\n",
       " 'ever': 517,\n",
       " 'control': 518,\n",
       " 'career': 519,\n",
       " 'produced': 520,\n",
       " 'perform': 521,\n",
       " '13': 522,\n",
       " 'highest': 523,\n",
       " 'institute': 524,\n",
       " 'earned': 525,\n",
       " 'popular': 526,\n",
       " '2002': 527,\n",
       " 'internet': 528,\n",
       " 'force': 529,\n",
       " 'upon': 530,\n",
       " 'digital': 531,\n",
       " 'help': 532,\n",
       " 'should': 533,\n",
       " 'commercial': 534,\n",
       " 'lower': 535,\n",
       " 'summer': 536,\n",
       " 'type': 537,\n",
       " 'association': 538,\n",
       " 'annual': 539,\n",
       " 'daily': 540,\n",
       " 'needed': 541,\n",
       " 'atticus': 542,\n",
       " 'judge': 543,\n",
       " 'james': 544,\n",
       " 'special': 545,\n",
       " 'mongol': 546,\n",
       " 'reached': 547,\n",
       " 'department': 548,\n",
       " 'lead': 549,\n",
       " 'western': 550,\n",
       " 'domestic': 551,\n",
       " 'countries': 552,\n",
       " 'john': 553,\n",
       " 'recorded': 554,\n",
       " 'weeks': 555,\n",
       " 'located': 556,\n",
       " 'cities': 557,\n",
       " 'liszt': 558,\n",
       " 'midna': 559,\n",
       " 'finale': 560,\n",
       " 'social': 561,\n",
       " 'france': 562,\n",
       " 'off': 563,\n",
       " 'contestant': 564,\n",
       " 'team': 565,\n",
       " 'man': 566,\n",
       " 'rescue': 567,\n",
       " 'opening': 568,\n",
       " 'we': 569,\n",
       " 'originally': 570,\n",
       " '8': 571,\n",
       " 'whom': 572,\n",
       " 'itunes': 573,\n",
       " 'online': 574,\n",
       " 'built': 575,\n",
       " 'approximately': 576,\n",
       " 'canis': 577,\n",
       " 'came': 578,\n",
       " 'together': 579,\n",
       " 'indian': 580,\n",
       " 'quake': 581,\n",
       " 'ceremony': 582,\n",
       " 'important': 583,\n",
       " 'born': 584,\n",
       " 'generally': 585,\n",
       " 'radio': 586,\n",
       " 'site': 587,\n",
       " '2003': 588,\n",
       " 'former': 589,\n",
       " 'again': 590,\n",
       " 'prior': 591,\n",
       " 'started': 592,\n",
       " 'relief': 593,\n",
       " 'few': 594,\n",
       " 'gautama': 595,\n",
       " 'featured': 596,\n",
       " 'couple': 597,\n",
       " 'mtv': 598,\n",
       " 'saying': 599,\n",
       " 'estimated': 600,\n",
       " 'chart': 601,\n",
       " 'get': 602,\n",
       " 'inspired': 603,\n",
       " 'person': 604,\n",
       " '21': 605,\n",
       " 'filming': 606,\n",
       " 'previously': 607,\n",
       " 'george': 608,\n",
       " 'species': 609,\n",
       " 'living': 610,\n",
       " '19': 611,\n",
       " 'stadium': 612,\n",
       " 'campaign': 613,\n",
       " 'founded': 614,\n",
       " 'local': 615,\n",
       " 'host': 616,\n",
       " 'efforts': 617,\n",
       " 'eventually': 618,\n",
       " 'appeared': 619,\n",
       " '200': 620,\n",
       " 'little': 621,\n",
       " 'metropolitan': 622,\n",
       " 'listed': 623,\n",
       " 'hit': 624,\n",
       " 'party': 625,\n",
       " 'night': 626,\n",
       " 'friends': 627,\n",
       " 'kind': 628,\n",
       " '14': 629,\n",
       " 'comprehensive': 630,\n",
       " 'point': 631,\n",
       " 'palace': 632,\n",
       " 'close': 633,\n",
       " 'council': 634,\n",
       " 'east': 635,\n",
       " 'armed': 636,\n",
       " 'down': 637,\n",
       " 'san': 638,\n",
       " 'wenchuan': 639,\n",
       " 'significant': 640,\n",
       " '50': 641,\n",
       " 'strong': 642,\n",
       " 'news': 643,\n",
       " 'protest': 644,\n",
       " 'good': 645,\n",
       " 'track': 646,\n",
       " 'fryderyk': 647,\n",
       " 'higher': 648,\n",
       " 'de': 649,\n",
       " 'joined': 650,\n",
       " 'carried': 651,\n",
       " 'months': 652,\n",
       " 'earlier': 653,\n",
       " 'moved': 654,\n",
       " 'path': 655,\n",
       " 'story': 656,\n",
       " 'minor': 657,\n",
       " 'premiered': 658,\n",
       " '2016': 659,\n",
       " 'political': 660,\n",
       " 'see': 661,\n",
       " 'decade': 662,\n",
       " 'free': 663,\n",
       " 'global': 664,\n",
       " 'audience': 665,\n",
       " 'events': 666,\n",
       " 'sasha': 667,\n",
       " 'fire': 668,\n",
       " 'community': 669,\n",
       " 'provided': 670,\n",
       " 'wolf': 671,\n",
       " 'fierce': 672,\n",
       " 'band': 673,\n",
       " 'viewers': 674,\n",
       " 'sent': 675,\n",
       " 'thought': 676,\n",
       " 'texts': 677,\n",
       " 'middle': 678,\n",
       " 'urban': 679,\n",
       " 'able': 680,\n",
       " 'entertainment': 681,\n",
       " 'generation': 682,\n",
       " 'tom': 683,\n",
       " 'least': 684,\n",
       " 'competition': 685,\n",
       " 'bridge': 686,\n",
       " 'placed': 687,\n",
       " 'label': 688,\n",
       " '16': 689,\n",
       " 'king': 690,\n",
       " 'poland': 691,\n",
       " 'yuan': 692,\n",
       " 'land': 693,\n",
       " 'voice': 694,\n",
       " 'variety': 695,\n",
       " 'referred': 696,\n",
       " 'karma': 697,\n",
       " 'common': 698,\n",
       " 'magazine': 699,\n",
       " 'copies': 700,\n",
       " 'hudson': 701,\n",
       " 'influenced': 702,\n",
       " 'birth': 703,\n",
       " 'say': 704,\n",
       " '40': 705,\n",
       " 'traditional': 706,\n",
       " 'nintendo': 707,\n",
       " 'market': 708,\n",
       " 'art': 709,\n",
       " 'practice': 710,\n",
       " 'process': 711,\n",
       " 'killed': 712,\n",
       " 'month': 713,\n",
       " 'across': 714,\n",
       " 'n': 715,\n",
       " 'character': 716,\n",
       " 'europe': 717,\n",
       " 'went': 718,\n",
       " 'security': 719,\n",
       " 'program': 720,\n",
       " 'died': 721,\n",
       " 'tradition': 722,\n",
       " 'design': 723,\n",
       " 'met': 724,\n",
       " 'concerts': 725,\n",
       " 'canada': 726,\n",
       " 'effort': 727,\n",
       " 'operations': 728,\n",
       " 'humans': 729,\n",
       " 'clothing': 730,\n",
       " 'actress': 731,\n",
       " 'ladies': 732,\n",
       " 'fifth': 733,\n",
       " 'run': 734,\n",
       " 'jackson': 735,\n",
       " 'increased': 736,\n",
       " 'case': 737,\n",
       " 'francisco': 738,\n",
       " 'featuring': 739,\n",
       " 'hollywood': 740,\n",
       " 'past': 741,\n",
       " 'similar': 742,\n",
       " 'go': 743,\n",
       " 'level': 744,\n",
       " 'round': 745,\n",
       " 'half': 746,\n",
       " 'successful': 747,\n",
       " 'hall': 748,\n",
       " 'ranked': 749,\n",
       " 'heat': 750,\n",
       " 'designed': 751,\n",
       " 'leading': 752,\n",
       " 'composed': 753,\n",
       " '23': 754,\n",
       " 'outside': 755,\n",
       " 'information': 756,\n",
       " 'recognized': 757,\n",
       " 'range': 758,\n",
       " 'hours': 759,\n",
       " 'effect': 760,\n",
       " 'eliminated': 761,\n",
       " 'response': 762,\n",
       " 'collection': 763,\n",
       " 'chicago': 764,\n",
       " 'polytechnic': 765,\n",
       " 'becoming': 766,\n",
       " 'kingdom': 767,\n",
       " 'private': 768,\n",
       " '26': 769,\n",
       " 'date': 770,\n",
       " 'prince': 771,\n",
       " 'trade': 772,\n",
       " 'once': 773,\n",
       " 'universities': 774,\n",
       " 'planned': 775,\n",
       " 'giving': 776,\n",
       " 'almost': 777,\n",
       " 'society': 778,\n",
       " 'opened': 779,\n",
       " 'scholars': 780,\n",
       " 'queens': 781,\n",
       " 'district': 782,\n",
       " '°c': 783,\n",
       " 'parents': 784,\n",
       " 'soundtrack': 785,\n",
       " 'store': 786,\n",
       " 'letter': 787,\n",
       " 'machine': 788,\n",
       " 'cause': 789,\n",
       " 'entire': 790,\n",
       " 'added': 791,\n",
       " 'research': 792,\n",
       " 'must': 793,\n",
       " 'yongle': 794,\n",
       " 'supporters': 795,\n",
       " 'airport': 796,\n",
       " 'am': 797,\n",
       " 'act': 798,\n",
       " 'uk': 799,\n",
       " '25': 800,\n",
       " 'either': 801,\n",
       " 'allowed': 802,\n",
       " 'teachings': 803,\n",
       " '6': 804,\n",
       " 'start': 805,\n",
       " 'personal': 806,\n",
       " 'addition': 807,\n",
       " 'technical': 808,\n",
       " 'beautiful': 809,\n",
       " 'ring': 810,\n",
       " 'wall': 811,\n",
       " 'overall': 812,\n",
       " 'foreign': 813,\n",
       " 'elements': 814,\n",
       " 'civil': 815,\n",
       " '’': 816,\n",
       " 'votes': 817,\n",
       " 'numberone': 818,\n",
       " '2001': 819,\n",
       " 'selling': 820,\n",
       " 'organization': 821,\n",
       " 'greatest': 822,\n",
       " 'plants': 823,\n",
       " 'attended': 824,\n",
       " 'appearance': 825,\n",
       " 'body': 826,\n",
       " 'wolves': 827,\n",
       " 'breeds': 828,\n",
       " 'torchbearers': 829,\n",
       " 'consecutive': 830,\n",
       " 'word': 831,\n",
       " 'true': 832,\n",
       " 'initially': 833,\n",
       " '17': 834,\n",
       " 'institutions': 835,\n",
       " 'engineering': 836,\n",
       " 'singing': 837,\n",
       " 'refused': 838,\n",
       " 'latter': 839,\n",
       " 'broadcast': 840,\n",
       " 'focus': 841,\n",
       " 'rather': 842,\n",
       " 'economic': 843,\n",
       " 'independent': 844,\n",
       " 'starting': 845,\n",
       " 'noted': 846,\n",
       " 'era': 847,\n",
       " 'find': 848,\n",
       " 'attempted': 849,\n",
       " 'sister': 850,\n",
       " 'me': 851,\n",
       " 'rock': 852,\n",
       " 'theme': 853,\n",
       " 'jersey': 854,\n",
       " 'station': 855,\n",
       " 'fault': 856,\n",
       " 'celebrity': 857,\n",
       " 'why': 858,\n",
       " 'status': 859,\n",
       " 'numerous': 860,\n",
       " 'foundation': 861,\n",
       " 'caused': 862,\n",
       " 'rate': 863,\n",
       " 'signed': 864,\n",
       " 'combined': 865,\n",
       " 'uses': 866,\n",
       " '35': 867,\n",
       " 'too': 868,\n",
       " 'animals': 869,\n",
       " '°f': 870,\n",
       " 'dukkha': 871,\n",
       " '18': 872,\n",
       " '80': 873,\n",
       " 'mind': 874,\n",
       " 'touch': 875,\n",
       " '60': 876,\n",
       " 'issue': 877,\n",
       " 'far': 878,\n",
       " 'worked': 879,\n",
       " 'ended': 880,\n",
       " 'army': 881,\n",
       " 'associated': 882,\n",
       " 'citation': 883,\n",
       " 'executive': 884,\n",
       " 'widely': 885,\n",
       " 'concerns': 886,\n",
       " 'involved': 887,\n",
       " 'network': 888,\n",
       " 'scenes': 889,\n",
       " 'authorities': 890,\n",
       " 'olympics': 891,\n",
       " 'african': 892,\n",
       " 'helped': 893,\n",
       " 'reviews': 894,\n",
       " 'movement': 895,\n",
       " 'particularly': 896,\n",
       " 'visited': 897,\n",
       " 'beginning': 898,\n",
       " 'mongols': 899,\n",
       " 'ability': 900,\n",
       " 'files': 901,\n",
       " 'coverage': 902,\n",
       " 'meditation': 903,\n",
       " 'give': 904,\n",
       " 'dutch': 905,\n",
       " 'archive': 906,\n",
       " 'teaching': 907,\n",
       " 'winter': 908,\n",
       " 'near': 909,\n",
       " 'skyfall': 910,\n",
       " 'soul': 911,\n",
       " 'girls': 912,\n",
       " 'experience': 913,\n",
       " 'recent': 914,\n",
       " 'website': 915,\n",
       " 'michael': 916,\n",
       " 'short': 917,\n",
       " 'town': 918,\n",
       " 'means': 919,\n",
       " 'nearly': 920,\n",
       " 'brought': 921,\n",
       " 'includes': 922,\n",
       " 'financial': 923,\n",
       " 'audio': 924,\n",
       " 'current': 925,\n",
       " 'provide': 926,\n",
       " 'grand': 927,\n",
       " 'soon': 928,\n",
       " '9': 929,\n",
       " 'save': 930,\n",
       " 'southern': 931,\n",
       " 'text': 932,\n",
       " 'demonstrators': 933,\n",
       " 'girl': 934,\n",
       " 'rapper': 935,\n",
       " 'failed': 936,\n",
       " 'vocal': 937,\n",
       " 'visit': 938,\n",
       " 'money': 939,\n",
       " 'taking': 940,\n",
       " 'compared': 941,\n",
       " 'real': 942,\n",
       " 'lived': 943,\n",
       " 'evidence': 944,\n",
       " 'selected': 945,\n",
       " 'royal': 946,\n",
       " 'characters': 947,\n",
       " 'province': 948,\n",
       " 'panel': 949,\n",
       " 'torchbearer': 950,\n",
       " 'irish': 951,\n",
       " 'debuted': 952,\n",
       " 'australia': 953,\n",
       " 'hospital': 954,\n",
       " 'fox': 955,\n",
       " 'presence': 956,\n",
       " 'showed': 957,\n",
       " 'frédéric': 958,\n",
       " 'cast': 959,\n",
       " 'tv': 960,\n",
       " 'washington': 961,\n",
       " 'turn': 962,\n",
       " 'oldest': 963,\n",
       " 'source': 964,\n",
       " 'affected': 965,\n",
       " 'nature': 966,\n",
       " 'troops': 967,\n",
       " 'committee': 968,\n",
       " 'member': 969,\n",
       " 'sound': 970,\n",
       " 'yet': 971,\n",
       " 'call': 972,\n",
       " 'maria': 973,\n",
       " 'dna': 974,\n",
       " 'followed': 975,\n",
       " 'themselves': 976,\n",
       " 'claimed': 977,\n",
       " 'stores': 978,\n",
       " 'class': 979,\n",
       " 'beichuan': 980,\n",
       " 'mentor': 981,\n",
       " '2000': 982,\n",
       " 'ruler': 983,\n",
       " 'open': 984,\n",
       " 'arrived': 985,\n",
       " 'director': 986,\n",
       " 'usually': 987,\n",
       " 'position': 988,\n",
       " 'noble': 989,\n",
       " 'gamecube': 990,\n",
       " 'replaced': 991,\n",
       " 'hip': 992,\n",
       " 'alongside': 993,\n",
       " 'thousands': 994,\n",
       " 'versions': 995,\n",
       " 'model': 996,\n",
       " 'legal': 997,\n",
       " 'japan': 998,\n",
       " 'attention': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
