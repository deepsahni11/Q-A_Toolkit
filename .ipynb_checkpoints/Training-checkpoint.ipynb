{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import logging\n",
    "import code\n",
    "import gc\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are two ways of letting the model know your intention i.e do you want to train the model or do you want to use the model to evaluate. In case of model.train() the model knows it has to learn the layers and when we use model.eval() it indicates the model that nothing new is to be learnt and the model is used for testing. model.eval() is also necessary because in pytorch if we are using batchnorm and during test if we want to just pass a single image, pytorch throws an error if model.eval() is not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Model:\n",
    "\n",
    "    def __init__(self, config, model):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "        self.parameters_trainable = list(filter(lambda p: p.requires_grad, self.model.parameters()))\n",
    "        self.optimizer = optim.Adam(self.parameters_trainable, lr=self.config.lr)\n",
    "#         self.word_to_index = pickle.load(open(os.path.join(config.data_dir, \"dictionaries.pkl\")))[\"word_to_index\"]\n",
    "#         self.index_to_word = pickle.load(open(os.path.join(config.data_dir, \"dictionaries.pkl\")))[\"index_to_word\"]\n",
    "        self.glove_path = os.path.join(config.data_dir, \"glove_word_embeddings.pkl\")\n",
    "        self.num_epochs = config.num_epochs\n",
    "        self.data_dir = config.data_dir\n",
    "        self.names = config.names\n",
    "        self.batch_size = config.batch_size\n",
    "        self.print_every = config.print_every\n",
    "        self.max_context_length = config.max_context_length\n",
    "        self.max_question_length = config.max_question_length\n",
    "#         self.emb_matrix, self.word2id, self.id2word = get_glove(self.glove_path, config.embedding_size)\n",
    "\n",
    "#         self.train_context_path = os.path.join(config.data_dir, \"train.context\")\n",
    "#         self.train_qn_path = os.path.join(config.data_dir, \"train.question\")\n",
    "#         self.train_ans_path = os.path.join(config.data_dir, \"train.span\")\n",
    "#         self.dev_context_path = os.path.join(config.data_dir, \"dev.context\")\n",
    "#         self.dev_qn_path = os.path.join(config.data_dir, \"dev.question\")\n",
    "#         self.dev_ans_path = os.path.join(config.data_dir, \"dev.span\")\n",
    "\n",
    "\n",
    "#     def update_param(self, loss):\n",
    "#         self.model.zero_grad()\n",
    "#         loss.backward()\n",
    "#         self.optimizer.step()\n",
    "    def get_data(self, batch, is_train=True):\n",
    "        \n",
    "        question_word_index_padded = batch.question_word_index_padded[0]\n",
    "        question_word_mask = (question_word_index_padded != 0).type(torch.int32)\n",
    "\n",
    "        context_word_index_padded = batch.context_word_index_padded[0]\n",
    "        context_word_mask = (context_word_index_padded != 0).type(torch.int32)\n",
    "        \n",
    "        span_tensor = batch.span_tensor\n",
    "#         print(.size())\n",
    "#         print(.size())\n",
    "#         answer_start = torch.unsqueeze(batch.answer_start[0], 1)\n",
    "#         answer_end = torch.unsqueeze(batch.answer_end[0], 1)\n",
    "#         print(torch.cat((answer_start, answer_end), 1))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        if is_train:\n",
    "#             span_tensor = torch.cat((answer_start, answer_end), 1)\n",
    "            return context_word_index_padded, context_word_mask, question_word_index_padded, question_word_mask, span_tensor\n",
    "        else:\n",
    "            return context_word_index_padded, context_word_mask, question_word_index_padded, question_word_mask\n",
    "      \n",
    "    def get_grad_norm(self, parameters, norm_type=2):\n",
    "        parameters = list(filter(lambda p: p.grad is not None, parameters))\n",
    "        total_norm = 0\n",
    "        for p in parameters:\n",
    "            param_norm = p.grad.data.norm(norm_type)\n",
    "            total_norm += param_norm ** norm_type\n",
    "        total_norm = total_norm ** (1. / norm_type)\n",
    "        return total_norm\n",
    "\n",
    "    def get_param_norm(self, parameters, norm_type=2):\n",
    "        total_norm = 0\n",
    "        for p in parameters:\n",
    "            param_norm = p.data.norm(norm_type)\n",
    "            total_norm += param_norm ** norm_type\n",
    "        total_norm = total_norm ** (1. / norm_type)\n",
    "        return total_norm\n",
    "        \n",
    "    def train_one_batch(self, batch, model, optimizer, parameters):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        context_word_index_padded, context_word_mask, question_word_index_padded, question_word_mask, span_tensor = self.get_data(batch)\n",
    "        \n",
    "#         context_word_indexes, context_word_mask, question_word_indexes, question_word_mask, answer_start, answer_end\n",
    "        loss, _, _ = model(context_word_index_padded, context_word_mask, question_word_index_padded, question_word_mask, span_tensor)\n",
    "\n",
    "        l2_reg = None\n",
    "        for W in parameters:\n",
    "            if l2_reg is None:\n",
    "                l2_reg = W.norm(2)\n",
    "            else:\n",
    "                l2_reg = l2_reg + W.norm(2)\n",
    "        loss = loss + config.reg_lambda * l2_reg\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        param_norm = self.get_param_norm(parameters)\n",
    "        grad_norm = self.get_grad_norm(parameters)\n",
    "\n",
    "        clip_grad_norm_(parameters, config.max_grad_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        return loss.item(), param_norm, grad_norm\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "\n",
    "\n",
    "        model = self.model\n",
    "        parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "        optimizer = Adam(parameters, lr=config.lr, amsgrad=True)\n",
    "\n",
    "        num_parameters = sum(p.numel() for p in parameters)\n",
    "        logging.info(\"Number of params: %d\" % num_parameters)\n",
    "\n",
    "        exp_loss, best_dev_f1, best_dev_em = None, None, None\n",
    "\n",
    "        epoch = 0\n",
    "        global_step = 0\n",
    "\n",
    "        logging.info(\"Beginning training loop...\")\n",
    "        for epoch in range(self.num_epochs):\n",
    "            epoch_tic = time.time()\n",
    "            for batch in get_batch_generator(self.data_dir, self.names, self.batch_size, self.max_context_length, self.max_question_length):\n",
    "\n",
    "                global_step += 1\n",
    "                iter_tic = time.time()\n",
    "\n",
    "                loss, param_norm, grad_norm = self.train_one_batch(batch, model, optimizer, parameters)\n",
    "    #             write_summary(loss, \"train/loss\", summary_writer, global_step)\n",
    "\n",
    "                iter_toc = time.time()\n",
    "                iter_time = iter_toc - iter_tic\n",
    "\n",
    "   \n",
    "\n",
    "                if global_step % self.print_every == 0:\n",
    "                    logging.info(\n",
    "                        'epoch %d, iter %d, loss %.5f, grad norm %.5f, param norm %.5f, batch time %.3f' %\n",
    "                        (epoch, global_step, loss,grad_norm, param_norm, iter_time))\n",
    "\n",
    "\n",
    "            epoch_toc = time.time()\n",
    "            logging.info(\"End of epoch %i. Time for epoch: %f\" % (epoch, epoch_toc - epoch_tic))\n",
    "\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refilling batches...\n",
      "Refilling batches took 6.87 seconds\n",
      "torch.Size([10, 401, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 400])\n",
      "tensor([[ 19,  22],\n",
      "        [ -1,  -1],\n",
      "        [ -1,  -1],\n",
      "        [ -1,  -1],\n",
      "        [ -1,  -1],\n",
      "        [ 83,  84],\n",
      "        [224, 225],\n",
      "        [350, 350],\n",
      "        [486, 486],\n",
      "        [ -1,  -1]])\n",
      "tensor([[-5.1764e+00, -5.1760e+00, -5.1732e+00,  ..., -1.0000e+30,\n",
      "         -1.0000e+30, -1.0000e+30],\n",
      "        [-5.1785e+00, -5.1794e+00, -5.1783e+00,  ..., -1.0000e+30,\n",
      "         -1.0000e+30, -1.0000e+30],\n",
      "        [-5.1766e+00, -5.1773e+00, -5.1802e+00,  ..., -1.0000e+30,\n",
      "         -1.0000e+30, -1.0000e+30],\n",
      "        ...,\n",
      "        [-5.9895e+00, -5.9919e+00, -5.9906e+00,  ..., -5.9962e+00,\n",
      "         -5.9920e+00, -5.9942e+00],\n",
      "        [-5.9911e+00, -5.9906e+00, -5.9887e+00,  ..., -5.9907e+00,\n",
      "         -5.9902e+00, -5.9925e+00],\n",
      "        [-5.9872e+00, -5.9926e+00, -5.9934e+00,  ..., -5.9900e+00,\n",
      "         -5.9928e+00, -5.9903e+00]], grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([ 19,  -1,  -1,  -1,  -1,  83, 224, 350, 486,  -1])\n",
      "tensor([ 19,   0,   0,   0,   0,  83, 224, 350, 486,   0])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at ..\\aten\\src\\THNN/generic/ClassNLLCriterion.c:92",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-230-322d6f66cbca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtrain_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrain_Model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-102-3b243b82d7c1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0miter_tic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m     \u001b[1;31m#             write_summary(loss, \"train/loss\", summary_writer, global_step)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-102-3b243b82d7c1>\u001b[0m in \u001b[0;36mtrain_one_batch\u001b[1;34m(self, batch, model, optimizer, parameters)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;31m#         context_word_indexes, context_word_mask, question_word_indexes, question_word_mask, answer_start, answer_end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext_word_index_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_word_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion_word_index_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion_word_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspan_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0ml2_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-191-3488bcba163c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, context_word_indexes, context_word_mask, question_word_indexes, question_word_mask, span_tensor)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m#         print(span_tensor[0].size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_word_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2870\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2880\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mspan_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2870\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2880\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_end\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-229-f25f24c1b455>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, U, document_word_sequence_mask, span_tensor)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[1;31m# Inputs to the Highway_Maxout_Network(to find start index) are: hidden_state_i(h_i), start_i_minus_1(index), u_concatenated ==>(u_start_i_minus_1;u_end_i_minus_1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             start_i_minus_1, curr_mask_start, step_loss_start = self.maxout_start(h_i, U, curr_mask_start, start_i_minus_1,\n\u001b[1;32m--> 163\u001b[1;33m                                                                 u_concatenated, mask_matrix, start_target)\n\u001b[0m\u001b[0;32m    164\u001b[0m             \u001b[0mu_start_i_minus_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_i_minus_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# b x 2l\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mu_concatenated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_i_minus_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_end_i_minus_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# b x 4l\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-229-f25f24c1b455>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, h_i, U, curr_mask_vector, index_i_minus_1, u_concatenated, mask_matrix, target)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m## from the predicted index at time-step (i-1)_th time-step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mstep_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# b\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;31m#             print(step_loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mstep_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep_loss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcurr_mask_vector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# b\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    940\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m--> 942\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m    943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2054\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2057\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1869\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   1870\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1871\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1872\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1873\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at ..\\aten\\src\\THNN/generic/ClassNLLCriterion.c:92"
     ]
    }
   ],
   "source": [
    "hidden_dim = 100\n",
    "dropout_ratio = 0.2\n",
    "maxout_pool_size=16\n",
    "max_number_of_iterations = 5\n",
    "with open(r\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\glove_word_embeddings.pkl\", \"rb\") as input_file:\n",
    "    embedding_matrix = pickle.load(input_file)\n",
    "model = DCN_Model(hidden_dim, embedding_matrix, dropout_ratio, maxout_pool_size, max_number_of_iterations)\n",
    "   \n",
    "# model = model.cpu()\n",
    "train_model = Train_Model(config, model)\n",
    "\n",
    "train_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#             if global_step % config.save_every == 0:\n",
    "#                 logging.info(\"Saving to %s...\" % model_dir)\n",
    "#                 self.save_model(model, optimizer, loss, global_step, epoch, model_dir)\n",
    "\n",
    "#             if global_step % config.eval_every == 0:\n",
    "#                 dev_loss = self.get_dev_loss(model)\n",
    "#                 logging.info(\"Epoch %d, Iter %d, dev loss: %f\" % (epoch, global_step, dev_loss))\n",
    "#                 write_summary(dev_loss, \"dev/loss\", summary_writer, global_step)\n",
    "\n",
    "#                 train_f1, train_em = self.check_f1_em(model, \"train\", num_samples=1000)\n",
    "#                 logging.info(\"Epoch %d, Iter %d, Train F1 score: %f, Train EM score: %f\" % (\n",
    "#                     epoch, global_step, train_f1, train_em))\n",
    "#                 write_summary(train_f1, \"train/F1\", summary_writer, global_step)\n",
    "#                 write_summary(train_em, \"train/EM\", summary_writer, global_step)\n",
    "\n",
    "#                 dev_f1, dev_em = self.check_f1_em(model, \"dev\", num_samples=0)\n",
    "#                 logging.info(\n",
    "#                     \"Epoch %d, Iter %d, Dev F1 score: %f, Dev EM score: %f\" % (epoch, global_step, dev_f1, dev_em))\n",
    "#                 write_summary(dev_f1, \"dev/F1\", summary_writer, global_step)\n",
    "#                 write_summary(dev_em, \"dev/EM\", summary_writer, global_step)\n",
    "\n",
    "#                 if best_dev_f1 is None or dev_f1 > best_dev_f1:\n",
    "#                     best_dev_f1 = dev_f1\n",
    "\n",
    "#                 if best_dev_em is None or dev_em > best_dev_em:\n",
    "#                     best_dev_em = dev_em\n",
    "#                     logging.info(\"Saving to %s...\" % bestmodel_dir)\n",
    "#                     self.save_model(model, optimizer, loss, global_step, epoch, bestmodel_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import tqdm as tqdm\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "# from data_util.vocab import PAD_ID, UNK_ID\n",
    "\n",
    "\"\"\"This file contains code to read tokenized data from file,\n",
    "truncate, pad and process it into batches ready for training\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Batch(object):\n",
    "    \"\"\"A class to hold the information needed for a training batch\"\"\"\n",
    "# Batch(names,context_word_index_padded, context_word_mask, question_word_index_padded, question_word_mask, answer_start, answer_end)\n",
    "    def __init__(self,names, context_word_index_padded, context_word_mask, question_word_index_padded, question_word_mask, span_tensor):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "          {context/qn}_ids: Numpy arrays.\n",
    "            Shape (batch_size, {context_len/question_len}). Contains padding.\n",
    "          {context/qn}_mask: Numpy arrays, same shape as _ids.\n",
    "            Contains 1s where there is real data, 0s where there is padding.\n",
    "          {context/qn/ans}_tokens: Lists length batch_size, containing lists (unpadded) of tokens (strings)\n",
    "          ans_span: numpy array, shape (batch_size, 2)\n",
    "          uuid: a list (length batch_size) of strings.\n",
    "            Not needed for training. Used by official_eval mode.\n",
    "        \"\"\"\n",
    "        self.names = names\n",
    "        self.context_word_index_padded = context_word_index_padded\n",
    "        self.context_word_mask = context_word_mask\n",
    "#         self.context_tokens = context_tokens\n",
    "\n",
    "        self.question_word_index_padded = question_word_index_padded\n",
    "        self.question_word_mask = question_word_mask\n",
    "#         self.qn_tokens = qn_tokens\n",
    "\n",
    "        self.span_tensor = span_tensor\n",
    "#         self.answer_end = answer_end\n",
    "\n",
    "#         self.uuids = uuids\n",
    "\n",
    "        self.batch_size = len(self.context_word_index_padded)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def refill_batches(batches,batch_size,names, max_context_length, max_question_length,span_tensor ):\n",
    "#     refill_batches(batches, word_to_index, context_file, qn_file, ans_file, batch_size, context_len, question_len, discard_long):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Adds more batches into the \"batches\" list.\n",
    "    Inputs:\n",
    "      batches: list to add batches to\n",
    "     \n",
    "      names: list containing strings of file names [\"train_context\",\"train_question\"] or [\"validation_context\",\"validation_question\"]\n",
    "      data_dir : paths to {train/dev}.{context/question/answer} data files\n",
    "      batch_size: integer ==> how big to make the batches\n",
    "      max_context_length, max_question_length: max length of context and question respectively\n",
    "      \n",
    "    \"\"\"\n",
    "    print (\"Refilling batches...\")\n",
    "    tic = time.time()\n",
    "    examples = [] # list of (qn_ids, context_ids, ans_span, ans_tokens) triples\n",
    "    \n",
    "    word_index_padded =[os.path.join(data_dir + name + \"_word_index_padded.pkl\")  for name in names ]\n",
    "    with open(word_index_padded[0], \"rb\") as input_file:\n",
    "        context_word_index_padded = pickle.load(input_file)\n",
    "    with open(word_index_padded[1], \"rb\") as input_file:\n",
    "        question_word_index_padded = pickle.load(input_file)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     context_line, qn_line, ans_line = context_file.readline(), qn_file.readline(), ans_file.readline() # read the next line from each\n",
    "\n",
    "    while True: # while you haven't reached the end\n",
    "        \n",
    "        # add to examples\n",
    "        examples.append((context_word_index_padded, question_word_index_padded, span_tensor))\n",
    "\n",
    "        # stop refilling if you have 1 batch : change it later \n",
    "        ################## add number of batches you need ###########################33\n",
    "        if len(examples) == batch_size * 1 :\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "    # Make into batches and append to the list batches\n",
    "    for batch_start in xrange(0, len(examples), batch_size):\n",
    "\n",
    "        # Note: each of these is a list length batch_size of lists of ints (except on last iter when it might be less than batch_size)\n",
    "        context_word_index_padded, question_word_index_padded,span_tensor = zip(*examples[batch_start:batch_start+batch_size])\n",
    "\n",
    "        batches.append((context_word_index_padded, question_word_index_padded,span_tensor))\n",
    "\n",
    "    # shuffle the batches\n",
    "    random.shuffle(batches)\n",
    "\n",
    "    toc = time.time()\n",
    "    print (\"Refilling batches took %.2f seconds\" % (toc-tic))\n",
    "    return\n",
    "\n",
    "\n",
    "def get_batch_generator(data_dir, names, batch_size, max_context_length, max_question_length):\n",
    "    \"\"\"\n",
    "    This function returns a generator object that yields batches.\n",
    "    The last batch in the dataset will be a partial batch.\n",
    "    Read this to understand generators and the yield keyword in Python: https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do\n",
    "    Inputs:\n",
    "      names: list containing strings of file names = [\"train_context\",\"train_question\"] or [\"validation_context\",\"validation_question\"]\n",
    "      data_dir : paths to {train/dev}.{context/question/answer} data files\n",
    "      batch_size: integer ==> how big to make the batches\n",
    "      max_context_length, max_question_length: max length of context and question respectively\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "#     with open(r\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\glove_word_embeddings.pkl\", \"rb\") as input_file:\n",
    "#         emb_matrix = pickle.load(input_file)\n",
    "    with open(data_dir + \"//\" + \"answer_end_pkl.pkl\", \"rb\") as input_file:\n",
    "        answer_end_pkl = pickle.load(input_file)\n",
    "    with open(data_dir + \"//\" + \"answer_start_pkl.pkl\", \"rb\") as input_file:\n",
    "        answer_start_pkl = pickle.load(input_file)\n",
    "\n",
    "    answer_end = torch.from_numpy(np.array([int(i) for i in answer_end_pkl])).long()\n",
    "    answer_start = torch.from_numpy(np.array([int(i) for i in answer_start_pkl])).long()              \n",
    "    answer_start = torch.unsqueeze(answer_start, 1)\n",
    "    answer_end = torch.unsqueeze(answer_end, 1)\n",
    "    \n",
    "    span_tensor = torch.cat((answer_start, answer_end), 1)\n",
    "    \n",
    "    batches = []\n",
    "\n",
    "    while True:\n",
    "        if len(batches) == 0: # add more batches\n",
    "            refill_batches(batches,batch_size,names, max_context_length, max_question_length,span_tensor)\n",
    "        if len(batches) == 0:\n",
    "            break\n",
    "\n",
    "        # Get next batch. These are all lists length batch_size\n",
    "        (context_word_index_padded, question_word_index_padded, span_tensor) = batches.pop(0)\n",
    "\n",
    "#         # Pad context_ids and qn_ids\n",
    "#         qn_ids = padded(qn_ids, question_len) # pad questions to length question_len\n",
    "#         context_ids = padded(context_ids, context_len) # pad contexts to length context_len\n",
    "\n",
    "        # Make qn_ids into a np array and create qn_mask\n",
    "#         qn_ids = np.array(qn_ids) # shape (batch_size, question_len)\n",
    "#         qn_mask = (qn_ids != PAD_ID).astype(np.int32) # shape (batch_size, question_len)\n",
    "\n",
    "#         # Make context_ids into a np array and create context_mask\n",
    "#         context_ids = np.array(context_ids) # shape (batch_size, context_len)\n",
    "#         context_mask = (context_ids != PAD_ID).astype(np.int32) # shape (batch_size, context_len)\n",
    "\n",
    "\n",
    "        context_word_mask = int(context_word_index_padded != 0)\n",
    "#     .int()\n",
    "#     .astype(torch.int32) \n",
    "        question_word_mask = int(question_word_index_padded != 0)\n",
    "#     .int()\n",
    "#     astype(torch.int32)\n",
    "        # Make ans_span into a np array\n",
    "#         ans_span = np.array(ans_span) # shape (batch_size, 2)\n",
    "\n",
    "        # Make into a Batch object\n",
    "        batch = Batch(names,context_word_index_padded, context_word_mask, question_word_index_padded, question_word_mask, span_tensor)\n",
    "\n",
    "        yield batch\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import logging\n",
    "import code\n",
    "import pickle\n",
    "import os\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Embedding\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "\n",
    "class DCN_Model(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, embedding_matrix, dropout_ratio, maxout_pool_size, max_number_of_iterations):\n",
    "        super(DCN_Model, self).__init__()\n",
    "\n",
    "        self.encoder = Word_Level_Encoder(hidden_dim, emb_matrix, dropout_ratio)\n",
    "        self.coattention_encoder = Coattention_Encoder(hidden_dim, maxout_pool_size, embedding_matrix, max_number_of_iterations, dropout_ratio)\n",
    "        self.decoder = Dynamic_Decoder(hidden_dim, maxout_pool_size, max_number_of_iterations, dropout_ratio)\n",
    "\n",
    "    def forward(self, context_word_indexes, context_word_mask, question_word_indexes, question_word_mask,span_tensor):\n",
    "        passage_representation = self.encoder.forward(context_word_indexes[2870:2880], context_word_mask[2870:2880])\n",
    "\n",
    "        question_representation = self.encoder.forward(question_word_indexes[2870:2880], question_word_mask[2870:2880])\n",
    "       \n",
    "\n",
    "        U_matrix = self.coattention_encoder.forward(question_representation, passage_representation,context_word_mask[2870:2880])\n",
    "\n",
    "#         print(span_tensor[0].size())\n",
    "\n",
    "        loss, index_start, index_end = self.decoder.forward(U_matrix, context_word_mask[2870:2880], (span_tensor[0])[2870:2880])\n",
    "\n",
    "        return loss, index_start, index_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "with open(r\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\glove_word_embeddings.pkl\", \"rb\") as input_file:\n",
    "    emb_matrix = pickle.load(input_file)\n",
    "    \n",
    "names = [\"validation_context\",\"train_context\",\"validation_question\",\"train_question\"]\n",
    "data_dir = \"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\\"\n",
    "\n",
    "word_index_padded =[os.path.join(data_dir + name + \"_word_index_padded.pkl\")  for name in names ]\n",
    "\n",
    "with open(word_index_padded[0], \"rb\") as input_file:\n",
    "    validation_context_word_index_padded = pickle.load(input_file)\n",
    "with open(word_index_padded[1], \"rb\") as input_file:\n",
    "    train_context_word_index_padded = pickle.load(input_file)\n",
    "with open(word_index_padded[2], \"rb\") as input_file:\n",
    "    validation_question_word_index_padded = pickle.load(input_file)\n",
    "with open(word_index_padded[3], \"rb\") as input_file:\n",
    "    train_question_word_index_padded = pickle.load(input_file)\n",
    "    \n",
    "validation_context_word_mask = (validation_context_word_index_padded != 0).type(torch.int32) \n",
    "train_context_word_mask = (train_context_word_index_padded != 0).type(torch.int32) \n",
    "validation_question_word_mask = (validation_question_word_index_padded != 0).type(torch.int32) \n",
    "train_question_word_mask = (train_question_word_index_padded != 0).type(torch.int32) \n",
    "\n",
    "\n",
    "def get_pretrained_embedding(embedding_matrix):\n",
    "    embedding = nn.Embedding(*embedding_matrix.shape)\n",
    "    embedding.weight = nn.Parameter(torch.from_numpy(embedding_matrix).float())\n",
    "    embedding.weight.requires_grad = False\n",
    "    return embedding\n",
    "\n",
    "\n",
    "# def init_lstm_forget_bias(lstm):\n",
    "#     for names in lstm._all_weights:\n",
    "#         for name in names:\n",
    "#             if name.startswith('bias_'):\n",
    "#                 # set forget bias to 1\n",
    "#                 bias = getattr(lstm, name)\n",
    "#                 n = bias.size(0)\n",
    "#                 start, end = n // 4, n // 2\n",
    "#                 bias.data.fill_(0.)\n",
    "#                 bias.data[start:end].fill_(1.)\n",
    "\n",
    "class Word_Level_Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, embedding_matrix, dropout_ratio):\n",
    "        super(Word_Level_Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = get_pretrained_embedding(embedding_matrix)\n",
    "        self.embedding_dim = self.embedding.embedding_dim\n",
    "\n",
    "        # batch_first = True\n",
    "        # Input: has a dimension of B * m * embedding_dim\n",
    "        # Function parameters: input_size, hidden_size, num_layers_of_LSTM = 1(here)\n",
    "        self.encoder = nn.LSTM(self.embedding_dim, hidden_dim, 1, batch_first=True,\n",
    "                              bidirectional=False, dropout=dropout_ratio) \n",
    "                                     \n",
    "#         init_lstm_forget_bias(self.encoder)\n",
    "        self.dropout_emb = nn.Dropout(p=dropout_ratio)\n",
    "        \n",
    "        # creates a random vector with size= hidden_dim\n",
    "        self.sentinel = nn.Parameter(torch.rand(hidden_dim,))\n",
    "\n",
    "    def forward(self, word_sequence_indexes, word_sequence_mask):\n",
    "#         # stores length of per instance for context/question\n",
    "        length_per_instance = torch.sum(word_sequence_mask, 1)\n",
    "#         print(length_per_instance)\n",
    "\n",
    "        # returns the word_sequences_embeddings_sorted matrix with the embeddings for each token/word from word_sequence_indexes_sorted\n",
    "        word_sequence_embeddings = self.embedding(word_sequence_indexes)\n",
    "        \n",
    "        # All RNN modules accept packed sequences as inputs.\n",
    "        # Input: word_sequence_embeddings_sorted has a dimension of B x m x l (l is the size of the glove_embedding/ pre-trained embedding/embedding_dim)\n",
    "        packed_word_sequence_embeddings = pack_padded_sequence(word_sequence_embeddings,length_per_instance,batch_first=True,enforce_sorted=False)\n",
    "        \n",
    "        # nn.LSTM encoder gets an input of pack_padded_sequence of dimensions: B x m x l (l is the embedding_dim)\n",
    "        # since the input was a packed sequence, the output will also be a packed sequence\n",
    "        output, _ = self.encoder(packed_word_sequence_embeddings)\n",
    "        \n",
    "        # Pads a packed batch of variable length sequences.\n",
    "        # It is an inverse operation to pack_padded_sequence().\n",
    "        output_to_LSTM_padded, _ = pad_packed_sequence(output, batch_first=True)\n",
    "        \n",
    "        # Returns a contiguous tensor containing the same data as self \n",
    "        output_to_LSTM_padded = output_to_LSTM_padded.contiguous()\n",
    "        \n",
    "        # dimension:  B x m x l\n",
    "        output_to_LSTM_padded = self.dropout_emb(output_to_LSTM_padded)\n",
    "\n",
    "        # list() creates a list of elements if an iterable is passed\n",
    "        batch_size, _ = list(word_sequence_mask.size())\n",
    "        \n",
    "        \n",
    "        sentinel_matrix = self.sentinel.unsqueeze(0).expand(batch_size, self.hidden_dim).unsqueeze(1).contiguous()  # B x 1 x l\n",
    "        length_per_instance = length_per_instance.unsqueeze(1).expand(batch_size, self.hidden_dim).unsqueeze(1)\n",
    "\n",
    "        # sentinel to be concatenated to the data\n",
    "        sentinel_zero = torch.zeros(batch_size, 1, self.hidden_dim)\n",
    "        \n",
    "        # copy sentinel vector at the end\n",
    "        output_to_LSTM_padded_with_sentinel = torch.cat([output_to_LSTM_padded, sentinel_zero], 1)  # B x (m + 1) x l\n",
    "        \n",
    "        \n",
    "        output_to_LSTM_padded_with_sentinel = output_to_LSTM_padded_with_sentinel.scatter_(1, length_per_instance, sentinel_matrix )\n",
    "\n",
    "        return output_to_LSTM_padded_with_sentinel\n",
    "    \n",
    "    \n",
    "hidden_dim = 300\n",
    "dropout_ratio = 0.2\n",
    "# encoder = Word_Level_Encoder(hidden_dim, emb_matrix, dropout_ratio)\n",
    "\n",
    "# e = encoder(validation_context_word_index_padded.type(torch.long)[:50],validation_context_word_mask[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception, closing connection.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2624, in run_cell\n",
      "    cell = self.input_transformer_manager.transform_cell(raw_cell)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 659, in transform_cell\n",
      "    self.push(cell)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 702, in push\n",
      "    out = self.push_line(line)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 743, in push_line\n",
      "    return super(IPythonInputSplitter, self).push(line)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 422, in push\n",
      "    self.code = self._compile(source, symbol=\"exec\")\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\codeop.py\", line 168, in __call__\n",
      "    return _maybe_compile(self.compiler, source, filename, symbol)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\codeop.py\", line 92, in _maybe_compile\n",
      "    code2 = compiler(source + \"\\n\\n\", filename, symbol)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\codeop.py\", line 134, in __call__\n",
      "    for feature in _features:\n",
      "KeyboardInterrupt\n",
      "ERROR:tornado.general:Uncaught exception, closing connection.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2624, in run_cell\n",
      "    cell = self.input_transformer_manager.transform_cell(raw_cell)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 659, in transform_cell\n",
      "    self.push(cell)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 702, in push\n",
      "    out = self.push_line(line)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 743, in push_line\n",
      "    return super(IPythonInputSplitter, self).push(line)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 422, in push\n",
      "    self.code = self._compile(source, symbol=\"exec\")\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\codeop.py\", line 168, in __call__\n",
      "    return _maybe_compile(self.compiler, source, filename, symbol)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\codeop.py\", line 92, in _maybe_compile\n",
      "    code2 = compiler(source + \"\\n\\n\", filename, symbol)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\codeop.py\", line 134, in __call__\n",
      "    for feature in _features:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class Highway_Maxout_Network(nn.Module):\n",
    "    def __init__(self, hidden_dim, maxout_pool_size, dropout_ratio):\n",
    "        super(Highway_Maxout_Network, self).__init__()\n",
    "        self.hidden_dim = hidden_dim # l\n",
    "        self.maxout_pool_size = maxout_pool_size # p\n",
    "\n",
    "        # Affine mapping from 5l ==> l\n",
    "        self.r = nn.Linear(5 * hidden_dim, hidden_dim, bias=False) \n",
    "       \n",
    "\n",
    "        # Affine mapping from 3*l ==> l*p\n",
    "        self.max_out_layer1 = nn.Linear(3 * hidden_dim, hidden_dim*maxout_pool_size)\n",
    "        \n",
    "        # Affine mapping from l ==> l*p\n",
    "        self.max_out_layer2 = nn.Linear(hidden_dim, hidden_dim*maxout_pool_size)\n",
    "       \n",
    "        # Affine mapping from 2*l ==> p\n",
    "        self.max_out_layer3 = nn.Linear(2 * hidden_dim, maxout_pool_size)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, h_i, U, curr_mask_vector, index_i_minus_1, u_concatenated, mask_matrix, target=None):\n",
    "        batch_size, max_word_length , _ = list(U.size())\n",
    "\n",
    "        # concatenation of ( h_i of dimension = b x l ; u_concatenated of dimension = b x 4l ) along dimension 1 = gives b x 5l\n",
    "        # self.r(b x 5l) ====> b x l (change of vector space)\n",
    "        r = F.tanh(self.r(torch.cat((h_i.view(-1, self.hidden_dim), u_concatenated), 1)))  # b x 5l => b x l\n",
    "       \n",
    "\n",
    "        # hidden_dim = l\n",
    "        r_expanded = r.unsqueeze(1).expand(batch_size, max_word_length, self.hidden_dim).contiguous()  # b x m x l\n",
    "\n",
    "        m_t1_input = torch.cat((U, r_expanded), 2).view(-1, 3*self.hidden_dim)  # b*m x 3l\n",
    "\n",
    "        m_t1_output = self.max_out_layer1(m_t1_input)  # b*m x p*l\n",
    "        \n",
    "        m_t1_output_resized, _ = m_t1_output.view(-1, self.hidden_dim, self.maxout_pool_size).max(2) # b*m x l\n",
    "\n",
    "        # m_t2_input =  m_t1_output_resized\n",
    "        m_t2_output = self.max_out_layer2(m_t1_output_resized)  # b*m x l*p\n",
    "        \n",
    "        m_t2_output_resized, _ = m_t2_output.view(-1, self.hidden_dim, self.maxout_pool_size).max(2)  # b*m x l\n",
    "\n",
    "        m_t3_input = torch.cat((m_t1_output_resized, m_t2_output_resized), 1)  # b*m x 2l\n",
    "        alpha = self.max_out_layer3(m_t3_input)  # b * m x p\n",
    "        alpha, _ = alpha.max(1)  # b*m\n",
    "        alpha = alpha.view(-1, max_word_length) # b x m\n",
    "\n",
    "        \n",
    "#         print(alpha.size())\n",
    "#         print(mask_matrix.size())\n",
    "        alpha = alpha + mask_matrix  # b x m\n",
    "        \n",
    "        # alpha can be treated as probabilities that assign probability masses todifferent words in context. The word with\n",
    "        # maximum weight(probability) becomes the index(start/end)\n",
    "        alpha = F.Softmax(alpha, 1)  # b x m\n",
    "        _, index_i = torch.max(alpha, dim=1) # b\n",
    "\n",
    "        if curr_mask_vector is None:\n",
    "            curr_mask_vector = (index_i == index_i) # b\n",
    "        else:\n",
    "            index_i = index_i*curr_mask_vector.long()  # b\n",
    "            index_i_minus_1 = index_i_minus_1*curr_mask_vector.long()  # b\n",
    "            curr_mask_vector = (index_i != index_i_minus_1) # b\n",
    "\n",
    "        step_loss = None\n",
    "\n",
    "        \n",
    "        print(alpha)\n",
    "        print(target)\n",
    "        target[target < 0] = 0\n",
    "        print(target)\n",
    "        ## loss is only calculated only on that the predicted index at i_th time-step which varies \n",
    "        ## from the predicted index at time-step (i-1)_th time-step\n",
    "        if target is not None:\n",
    "            step_loss = self.loss(alpha, target)  # b\n",
    "#             print(step_loss)\n",
    "            step_loss = step_loss * curr_mask_vector.float() # b\n",
    "\n",
    "        return index_i, curr_mask_vector, step_loss # all have dimension: b\n",
    "\n",
    "class Dynamic_Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, maxout_pool_size, max_number_of_iterations, dropout_ratio):\n",
    "        super(Dynamic_Decoder, self).__init__()\n",
    "        self.max_number_of_iterations = max_number_of_iterations\n",
    "        \n",
    "        # batch_first = True\n",
    "        # Input: has a dimension of B * m * embedding_dim\n",
    "        # Function parameters: input_size, hidden_size, num_layers_of_LSTM = 1(here)\n",
    "        self.decoder = nn.LSTM(4 * hidden_dim, hidden_dim, 1, batch_first=True, bidirectional=False)\n",
    "#         init_lstm_forget_bias(self.decoder)\n",
    "\n",
    "        self.maxout_start = Highway_Maxout_Network(hidden_dim, maxout_pool_size, dropout_ratio)\n",
    "        self.maxout_end = Highway_Maxout_Network(hidden_dim, maxout_pool_size, dropout_ratio)\n",
    "\n",
    "    def forward(self, U, document_word_sequence_mask,span_tensor):\n",
    "        batch_size, max_word_length, _ = list(U.size()) # U has dimension : B x m x 2l\n",
    "\n",
    "        curr_mask_start,  curr_mask_end = None, None\n",
    "        results_mask_start, results_start = [], []\n",
    "        results_mask_end, results_end = [], []\n",
    "        step_losses = []\n",
    "        \n",
    "        print(document_word_sequence_mask.size())\n",
    "\n",
    "        mask_matrix = (1.0 - document_word_sequence_mask.float()) * (-1e30)\n",
    "        indices = torch.arange(0, batch_size, out=torch.LongTensor(batch_size))\n",
    "\n",
    "        # initialize start_zero, end_zero: these are the initial values of start and end indices\n",
    "        # start_i_minus_1 = the first index for the context/question \n",
    "        # end_i_minus_1 = the last index for the context/question \n",
    "        start_i_minus_1 = torch.zeros(batch_size, ).long()\n",
    "        end_i_minus_1 = torch.sum(document_word_sequence_mask, 1) - 1\n",
    "\n",
    "        \n",
    "\n",
    "        # After every iteration the hidden and current state \n",
    "        # at t = length of the sequence (for the one-directional lstm) will\n",
    "        # be returned by the lstm\n",
    "        # the hidden_state_i(h_i) will serve as an input to next lstm\n",
    "        hidden_and_current_state_i = None\n",
    "        start_target = None\n",
    "        end_target = None\n",
    "        \n",
    "        # this sets the start and end target (ie. the y_label) for an answer\n",
    "        \n",
    "        print(span_tensor)\n",
    "        \n",
    "        if span_tensor is not None:\n",
    "            start_target = span_tensor[:,0]\n",
    "            end_target = span_tensor[:,1]\n",
    "            \n",
    "        # this is just an initialization of u_start\n",
    "        # u_start_i_minus_1 is essentially u_start_zero outside the loop\n",
    "        u_start_i_minus_1 = U[indices, start_i_minus_1, :]  # b x 2l\n",
    "        \n",
    "        # Why do we need an iterative procedure to predict the start and end indices for na answer ? \n",
    "        # Solution: there may exist several intuitive answer spans within the document, each corresponding to a\n",
    "        # local maxima. An iterative technique to select an answer span by alternating between\n",
    "        # predicting the start point and predicting the end point. This iterative procedure allows the model to\n",
    "        # recover from initial local maxima corresponding to incorrect answer spans.\n",
    "        for _ in range(self.max_number_of_iterations):\n",
    "            u_end_i_minus_1 = U[indices, end_i_minus_1, :]  # b x 2l\n",
    "            \n",
    "            # u_concatenated is fed to the lstm\n",
    "            u_concatenated = torch.cat((u_start_i_minus_1, u_end_i_minus_1), 1)  # b x 4l\n",
    "\n",
    "            # the hidden_and_current_state_i = h_i,c_i are essentially hidden and current cell states \n",
    "            # for t = length of the sequence (for the one-directional lstm) after every iteration\n",
    "            lstm_output, hidden_and_current_state_i = self.decoder(u_concatenated.unsqueeze(1), hidden_and_current_state_i)\n",
    "            h_i, c_i = hidden_and_current_state_i\n",
    "\n",
    "            # Inputs to the Highway_Maxout_Network(to find start index) are: hidden_state_i(h_i), start_i_minus_1(index), u_concatenated ==>(u_start_i_minus_1;u_end_i_minus_1) \n",
    "            start_i_minus_1, curr_mask_start, step_loss_start = self.maxout_start(h_i, U, curr_mask_start, start_i_minus_1,\n",
    "                                                                u_concatenated, mask_matrix, start_target)\n",
    "            u_start_i_minus_1 = U[indices, start_i_minus_1, :]  # b x 2l\n",
    "            u_concatenated = torch.cat((start_i_minus_1, u_end_i_minus_1), 1)  # b x 4l\n",
    "\n",
    "            # Inputs to the Highway_Maxout_Network(to find end index) are: hidden_state_i(h_i), end_i_minus_1(index), u_concatenated ==>(u_start_i_minus_1;u_end_i_minus_1) \n",
    "            end_i_minus_1, curr_mask_end, step_loss_end = self.maxout_end(h_i, U, curr_mask_end, end_i_minus_1,\n",
    "                                                              u_concatenated, mask_matrix, end_target)\n",
    "\n",
    "            # we minimize the cumulative softmax cross entropy of the start and end points across all iterations.\n",
    "            if span_tensor is not None:\n",
    "                step_loss = step_loss_start + step_loss_end\n",
    "                step_losses.append(step_loss)\n",
    "\n",
    "            \n",
    "            results_mask_start.append(curr_mask_start) # appends all the curr_mask_start ==> dimension: b x num_iterations\n",
    "            results_start.append(start_i_minus_1) # appends all the start_indexes ==> dimension: b x num_iterations\n",
    "            results_mask_end.append(curr_mask_end) # appends all the curr_mask_end ==> dimension: b x num_iterations\n",
    "            results_end.append(end_i_minus_1) # appends all the end_indexes ==> dimension: b x num_iterations\n",
    "\n",
    "        result_pos_start = torch.sum(torch.stack(results_mask_start, 1), 1).long()\n",
    "        result_pos_start = result_pos_start - 1\n",
    "        index_start = torch.gather(torch.stack(results_start, 1), 1, result_pos_start.unsqueeze(1)).squeeze()\n",
    "\n",
    "        result_pos_end = torch.sum(torch.stack(results_mask_end, 1), 1).long()\n",
    "        result_pos_end = result_pos_end - 1\n",
    "        index_end = torch.gather(torch.stack(results_end, 1), 1, result_pos_end.unsqueeze(1)).squeeze()\n",
    "\n",
    "        loss = None\n",
    "\n",
    "        if span_tensor is not None:\n",
    "            sum_losses = torch.sum(torch.stack(step_losses, 1), 1)\n",
    "            batch_avg_loss = sum_losses / self.max_number_of_iterations\n",
    "            loss = torch.mean(batch_avg_loss)\n",
    "\n",
    "        return loss, index_start, index_end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "class Coattention_Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, maxout_pool_size, embedding_matrix, max_number_of_iterations, dropout_ratio):\n",
    "        super(Coattention_Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "#         self.encoder = Word_Level_Encoder(hidden_dim, embedding_matrix, dropout_ratio)\n",
    "\n",
    "        ## nn.Linear(input_dim, output_dim)\n",
    "        self.question_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.fusion_bilstm = Fusion_BiLSTM(hidden_dim, dropout_ratio)\n",
    "#         self.decoder = Dynamic_Decoder(hidden_dim, maxout_pool_size, max_number_of_iterations, dropout_ratio)\n",
    "        self.dropout = nn.Dropout(p=dropout_ratio)\n",
    "\n",
    "    def forward(self, question_representation, context_representation,document_word_sequence_mask):\n",
    "        \n",
    "        ############## m = number of instances in document ;  n= number of instances in question ############################33\n",
    "        Q = question_representation # B x (n + 1) x l\n",
    "        D = context_representation  # B x (m + 1) x l\n",
    "        \n",
    "        print(D.size())\n",
    "\n",
    "        # view function is meant to reshape the tensor.(Similar to reshape function in numpy)\n",
    "        # view( row_size = -1 ,means that number of rows are unknown, column_size)\n",
    "        \n",
    "        \n",
    "        # pass the Q tensor through a non-linearity \n",
    "        Q = F.tanh(self.question_proj(Q.view(-1, self.hidden_dim))).view(Q.size()) #B x (n + 1) x l\n",
    "\n",
    "        ##################################   Co-Attention starts here  #######################################\n",
    "        \n",
    "        ########################################   Step - 1  ##################################################\n",
    "        # transpose(tensor, first_dimension to be transposed, second_dimension to be transposed)\n",
    "        Q_transpose = torch.transpose(Q, 1, 2) #dimension: B x l x (n + 1)\n",
    "        \n",
    "        # Performs a batch matrix-matrix product of matrices stored in batch1 and batch2.\n",
    "        # batch1 and batch2 must be 3-D tensors each containing the same number of matrices.\n",
    "        L = torch.bmm(D, Q_transpose) # dimension of L : B x (m + 1) x (n + 1)\n",
    "\n",
    "        ####################################### Step-2 ######################################################\n",
    "        A_Q = F.softmax(L, dim=2) # B x (m + 1) x (n + 1)\n",
    "\n",
    "\n",
    "        D_transpose = torch.transpose(D, 1, 2) #dimension: B x l x (m + 1)\n",
    "        C_Q = torch.bmm(D_transpose, A_Q) # (B x l x (m + 1)) x (B x (m + 1) x (n + 1)) => B x l x (n + 1)\n",
    "\n",
    "        ####################################### Step-3 #######################################################\n",
    "        L_tranpose = torch.transpose(L,1,2)\n",
    "        A_D = F.softmax(L_tranpose, dim=2)  # B x (n + 1) x (m + 1)\n",
    "        \n",
    "        \n",
    "        # concatenation along dimension=1:(B x l x (n + 1) ; B x l x (n + 1)  -----> B x 2l x (n + 1) ) x (B x (n + 1) x (m + 1)) ====> B x 2l x (m + 1)\n",
    "        C_D = torch.bmm(torch.cat((Q_transpose, C_Q), 1), A_D) # B x 2l x (m + 1)\n",
    "        C_D_transpose = torch.transpose(C_D, 1, 2)  # B x (m + 1) x 2l\n",
    "\n",
    "        \n",
    "        #######################################  Step-4 ##########################################################\n",
    "        #fusion BiLSTM\n",
    "        # concatenation along dimension = 2:  (B x (m + 1) x 2l ; B x (m + 1) x l  -----> B x (m + 1) x 3l )\n",
    "        bi_lstm_input = torch.cat((C_D_transpose, D), 2) # B x (m + 1) x 3l\n",
    "        bi_lstm_input = self.dropout(bi_lstm_input)\n",
    "        \n",
    "        \n",
    "       \n",
    "        U = self.fusion_bilstm(bi_lstm_input, document_word_sequence_mask) # B x m x 2l\n",
    "        \n",
    "#         print(U.size())\n",
    "        \n",
    "        return U\n",
    "\n",
    "#         loss, index_start, index_end = self.decoder(U, document_word_sequence_mask, answer_start, answer_end)\n",
    "#         if answer_start is not None:\n",
    "#             return loss, index_start, index_end\n",
    "#         else:\n",
    "#             return index_start, index_end\n",
    "\n",
    "\n",
    "class Fusion_BiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout_ratio):\n",
    "        super(Fusion_BiLSTM, self).__init__()\n",
    "         # batch_first = True\n",
    "        # Input: has a dimension of B * m * embedding_dim\n",
    "        # Function parameters: input_size, hidden_size, num_layers_of_LSTM = 1(here)\n",
    "        self.fusion_bilstm = nn.LSTM(3 * hidden_dim, hidden_dim, 1, batch_first=True,\n",
    "                                     bidirectional=True, dropout=dropout_ratio)\n",
    "#         init_lstm_forget_bias(self.fusion_bilstm)\n",
    "        self.dropout = nn.Dropout(p=dropout_ratio)\n",
    "\n",
    "    def forward(self, word_sequence_embeddings, word_sequence_mask):\n",
    "        \n",
    "        # stores length of per instance for context/question\n",
    "        length_per_instance = torch.sum(word_sequence_mask, 1)\n",
    "        \n",
    "        # sorts the length_per_instance vector in decreasing order\n",
    "        length_per_instance_sorted, length_per_instance_argsort = torch.sort(length_per_instance, 0, True) \n",
    "        \n",
    "        _, length_per_instance_argsort_argsort = torch.sort(length_per_instance_argsort, 0)\n",
    "        \n",
    "        # selects the word indexes from word_sequences_indexes matrix according to of length_per_instance_argsort\n",
    "        word_sequence_embeddings_sorted = torch.index_select(word_sequence_embeddings, 0, length_per_instance_argsort)\n",
    "\n",
    "      \n",
    "        # All RNN modules accept packed sequences as inputs.\n",
    "        # Input: word_sequence_embeddings_sorted has a dimension of B x m x l (l is the size of the glove_embedding/ pre-trained embedding/embedding_dim)\n",
    "        packed_word_sequence_embeddings_sorted = pack_padded_sequence(word_sequence_embeddings_sorted, length_per_instance_sorted, batch_first=True)\n",
    "        \n",
    "        # nn.LSTM encoder gets an input of pack_padded_sequence of dimensions: B x m x l (l is the embedding_dim)\n",
    "        # since the input was a packed sequence, the output will also be a packed sequence\n",
    "        output, _ = self.fusion_bilstm(packed_word_sequence_embeddings_sorted)\n",
    "        \n",
    "        # Pads a packed batch of variable length sequences.\n",
    "        # It is an inverse operation to pack_padded_sequence().\n",
    "        output_to_BiLSTM_padded, _ = pad_packed_sequence(output, batch_first=True)\n",
    "        \n",
    "        # Returns a contiguous tensor containing the same data as self \n",
    "        output_to_BiLSTM_padded = output_to_BiLSTM_padded.contiguous()\n",
    "        \n",
    "        # dimension:  B x m x l\n",
    "        output_to_BiLSTM_padded_sorted = torch.index_select(output_to_BiLSTM_padded, 0, length_per_instance_argsort_argsort)  \n",
    "        output_to_BiLSTM_padded_sorted = self.dropout(output_to_BiLSTM_padded_sorted)\n",
    "\n",
    "        return output_to_BiLSTM_padded_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Config(object):\n",
    "    pass\n",
    "\n",
    "config = Config()\n",
    "config.data_dir = \"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\\"\n",
    "config.word_embedding_size = 100\n",
    "config.hidden_dim = 300\n",
    "config.dropout_ratio = 0.15\n",
    "config.max_context_length = 600\n",
    "config.max_question_length = 30\n",
    "\n",
    "\n",
    "#vector with zeros for unknown words\n",
    "config.num_iterations = 4\n",
    "config.maxout_pool_size=16\n",
    "\n",
    "config.lr = 0.001\n",
    "config.dropout_ratio = 0.15\n",
    "\n",
    "config.max_grad_norm = 5.0\n",
    "config.batch_size = 1\n",
    "config.num_epochs = 50\n",
    "\n",
    "# config.print_every = 100\n",
    "# config.save_every = 50000000\n",
    "# config.eval_every = 1000\n",
    "\n",
    "# config.model_type = 'co-attention'\n",
    "config.reg_lambda = 0.00007\n",
    "config.names = [\"train_context\",\"train_question\"]\n",
    "config.print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\train_word_index.context_pkl.pkl\", \"rb\") as input_file:\n",
    "    train_word_index = pickle.load(input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_index = (np.array(train_word_index))\n",
    "train_word_index = np.sort(train_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((train_word_index)[2880])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
