{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import logging\n",
    "import code\n",
    "import gc\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are two ways of letting the model know your intention i.e do you want to train the model or do you want to use the model to evaluate. In case of model.train() the model knows it has to learn the layers and when we use model.eval() it indicates the model that nothing new is to be learnt and the model is used for testing. model.eval() is also necessary because in pytorch if we are using batchnorm and during test if we want to just pass a single image, pytorch throws an error if model.eval() is not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Model:\n",
    "\n",
    "    def __init__(self, config, model):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "        self.parameters_trainable = list(filter(lambda p: p.requires_grad, self.model.parameters()))\n",
    "        self.optimizer = optim.Adam(self.parameters_trainable, lr=self.config.lr)\n",
    "#         self.word_to_index = pickle.load(open(os.path.join(config.data_dir, \"dictionaries.pkl\")))[\"word_to_index\"]\n",
    "#         self.index_to_word = pickle.load(open(os.path.join(config.data_dir, \"dictionaries.pkl\")))[\"index_to_word\"]\n",
    "        self.glove_path = os.path.join(config.data_dir, \"glove_word_embeddings.pkl\")\n",
    "        self.num_epochs = config.num_epochs\n",
    "        self.data_dir = config.data_dir\n",
    "        self.names = config.names\n",
    "        self.batch_size = config.batch_size\n",
    "        self.print_every = config.print_every\n",
    "        self.max_context_length = config.max_context_length\n",
    "        self.max_question_length = config.max_question_length\n",
    "#         self.emb_matrix, self.word2id, self.id2word = get_glove(self.glove_path, config.embedding_size)\n",
    "\n",
    "#         self.train_context_path = os.path.join(config.data_dir, \"train.context\")\n",
    "#         self.train_qn_path = os.path.join(config.data_dir, \"train.question\")\n",
    "#         self.train_ans_path = os.path.join(config.data_dir, \"train.span\")\n",
    "#         self.dev_context_path = os.path.join(config.data_dir, \"dev.context\")\n",
    "#         self.dev_qn_path = os.path.join(config.data_dir, \"dev.question\")\n",
    "#         self.dev_ans_path = os.path.join(config.data_dir, \"dev.span\")\n",
    "\n",
    "\n",
    "#     def update_param(self, loss):\n",
    "#         self.model.zero_grad()\n",
    "#         loss.backward()\n",
    "#         self.optimizer.step()\n",
    "    def get_data(self, batch, is_train=True):\n",
    "        \n",
    "        question_word_index_batch = batch.question_word_index_batch\n",
    "#         question_word_mask = batch.question_word_mask\n",
    "\n",
    "        context_word_index_batch = batch.context_word_index_batch\n",
    "#         context_word_mask = batch.context_word_mask\n",
    "        \n",
    "        span_tensor_batch = batch.span_tensor_batch\n",
    "#         print(question_word_mask.size())\n",
    "#         print(question_word_index_padded.size())\n",
    "#         print(.size())\n",
    "#         answer_start = torch.unsqueeze(batch.answer_start[0], 1)\n",
    "#         answer_end = torch.unsqueeze(batch.answer_end[0], 1)\n",
    "#         print(torch.cat((answer_start, answer_end), 1))\n",
    "\n",
    "#         print(question_word_index_padded)\n",
    "#         print(span_tensor)\n",
    "        \n",
    "        \n",
    "        if is_train:\n",
    "#             span_tensor = torch.cat((answer_start, answer_end), 1)\n",
    "            return context_word_index_batch, question_word_index_batch,span_tensor_batch\n",
    "        else:\n",
    "            return context_word_index_batch, question_word_index_batch\n",
    "      \n",
    "    def get_grad_norm(self, parameters, norm_type=2):\n",
    "        parameters = list(filter(lambda p: p.grad is not None, parameters))\n",
    "        total_norm = 0\n",
    "        for p in parameters:\n",
    "            param_norm = p.grad.data.norm(norm_type)\n",
    "            total_norm += param_norm ** norm_type\n",
    "        total_norm = total_norm ** (1. / norm_type)\n",
    "        return total_norm\n",
    "\n",
    "    def get_param_norm(self, parameters, norm_type=2):\n",
    "        total_norm = 0\n",
    "        for p in parameters:\n",
    "            param_norm = p.data.norm(norm_type)\n",
    "            total_norm += param_norm ** norm_type\n",
    "        total_norm = total_norm ** (1. / norm_type)\n",
    "        return total_norm\n",
    "        \n",
    "    def train_one_batch(self, batch, model, optimizer, parameters):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        context_word_index_batch, question_word_index_batch,  span_tensor_batch = self.get_data(batch)\n",
    "        \n",
    "#         print(\"span_tensor_batch\")\n",
    "#         print(span_tensor_batch)\n",
    "        \n",
    "#         print(\"context_word_index_batch\")\n",
    "#         print(np.shape(context_word_index_batch))\n",
    "        \n",
    "        context_word_index_padded_per_batch = pad_data(context_word_index_batch)\n",
    "        question_word_index_padded_per_batch = pad_data(question_word_index_batch)\n",
    "        \n",
    "#         print(\"context_word_index_padded_per_batch\")\n",
    "#         print(np.shape(context_word_index_padded_per_batch))\n",
    "#         print(context_word_index_padded_per_batch)\n",
    "#         context_word_index_padded_per_batch_new = torch.from_numpy(context_word_index_padded_per_batch)\n",
    "        context_ids = np.array(context_word_index_padded_per_batch) # shape (batch_size, context_len)\n",
    "        context_mask_per_batch = (context_ids != 0).astype(np.int32) # shape (batch_size, context_len)\n",
    "        context_word_mask_per_batch_new = torch.from_numpy(context_mask_per_batch)\n",
    "\n",
    "#         question_word_index_padded_per_batch_new = torch.from_numpy(question_word_index_padded_per_batch)\n",
    "        question_ids = np.array(question_word_index_padded_per_batch) # shape (batch_size, context_len)\n",
    "        question_mask_per_batch = (question_ids != 0).astype(np.int32) # shape (batch_size, context_len)\n",
    "        question_word_mask_per_batch_new = torch.from_numpy(question_mask_per_batch)\n",
    "\n",
    "#         print(\"context_word_index_padded_per_batch\")\n",
    "\n",
    "#         print(context_word_index_padded_per_batch)\n",
    "#         print(\"context_word_mask_per_batch_new\")\n",
    "#         print(context_word_mask_per_batch_new)\n",
    "        \n",
    "#         print(context_word_mask.size())\n",
    "        loss, _, _ = model(context_word_index_padded_per_batch,context_word_mask_per_batch_new, question_word_index_padded_per_batch, question_word_mask_per_batch_new, span_tensor_batch)\n",
    "\n",
    "        l2_reg = None\n",
    "        for W in parameters:\n",
    "            if l2_reg is None:\n",
    "                l2_reg = W.norm(2)\n",
    "            else:\n",
    "                l2_reg = l2_reg + W.norm(2)\n",
    "        loss = loss + config.reg_lambda * l2_reg\n",
    "        \n",
    "        print(loss)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        param_norm = self.get_param_norm(parameters)\n",
    "        grad_norm = self.get_grad_norm(parameters)\n",
    "\n",
    "#         clip_grad_norm_(parameters, config.max_grad_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        return loss.item(), param_norm, grad_norm\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "\n",
    "\n",
    "        model = self.model\n",
    "        parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "        optimizer = Adam(parameters, lr=config.lr, amsgrad=True)\n",
    "\n",
    "        num_parameters = sum(p.numel() for p in parameters)\n",
    "        logging.info(\"Number of params: %d\" % num_parameters)\n",
    "\n",
    "        exp_loss, best_dev_f1, best_dev_em = None, None, None\n",
    "\n",
    "        epoch = 0\n",
    "        global_step = 0\n",
    "\n",
    "        logging.info(\"Beginning training loop...\")\n",
    "#         self.num_epochs\n",
    "        for epoch in range(1):\n",
    "            epoch_tic = time.time()\n",
    "            for batch in get_batch_generator(self.data_dir, self.names, self.batch_size, self.max_context_length, self.max_question_length):\n",
    "\n",
    "                global_step += 1\n",
    "                iter_tic = time.time()\n",
    "\n",
    "                \n",
    "                loss, param_norm, grad_norm = self.train_one_batch(batch, model, optimizer, parameters)\n",
    "    #             write_summary(loss, \"train/loss\", summary_writer, global_step)\n",
    "\n",
    "                print(\"loss for batch\" + str(global_step) + \" = \" + str(loss))\n",
    "    \n",
    "                iter_toc = time.time()\n",
    "                iter_time = iter_toc - iter_tic\n",
    "\n",
    "   #             if global_step % self.print_every == 0:\n",
    "#                     logging.info(\n",
    "#                         'epoch %d, iter %d, loss %.5f, grad norm %.5f, param norm %.5f, batch time %.3f' %\n",
    "#                         (epoch, global_step, loss,grad_norm, param_norm, iter_time))\n",
    "\n",
    "\n",
    "            epoch_toc = time.time()\n",
    "            logging.info(\"End of epoch %i. Time for epoch: %f\" % (epoch, epoch_toc - epoch_tic))\n",
    "\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refilling batches...\n",
      "Refilling batches took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 5030.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_representation.(Output to Encoder Layer) ==  torch.Size([5, 18, 100])\n",
      "context_representation. (Output to Encoder Layer)  ==  torch.Size([5, 304, 100])\n",
      "size of U.(U is output of Co-attention encoder) ==  torch.Size([5, 303, 200])\n",
      "span tensor : torch.Size([5, 2])\n",
      "tensor(3.4463, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: RuntimeWarning: Traceback of forward call that caused the error:\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-286-1bd804145350>\", line 14, in <module>\n",
      "    train_model.train()\n",
      "  File \"<ipython-input-285-8fb4f275763c>\", line 158, in train\n",
      "    loss, param_norm, grad_norm = self.train_one_batch(batch, model, optimizer, parameters)\n",
      "  File \"<ipython-input-285-8fb4f275763c>\", line 110, in train_one_batch\n",
      "    loss, _, _ = model(context_word_index_padded_per_batch,context_word_mask_per_batch_new, question_word_index_padded_per_batch, question_word_mask_per_batch_new, span_tensor_batch)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-224-397468b5a9d4>\", line 35, in forward\n",
      "    loss, index_start, index_end = self.decoder.forward(U_matrix, context_word_mask, span_tensor)\n",
      "  File \"<ipython-input-283-db340674f774>\", line 169, in forward\n",
      "    u_concatenated, mask_matrix, start_target)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-283-db340674f774>\", line 89, in forward\n",
      "    step_loss = self.loss(alpha4, target)  # b\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\", line 942, in forward\n",
      "    ignore_index=self.ignore_index, reduction=self.reduction)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 2056, in cross_entropy\n",
      "    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 1871, in nll_loss\n",
      "    ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.LongTensor [5]] is at version 10; expected version 9 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-286-1bd804145350>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtrain_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrain_Model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-285-8fb4f275763c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m     \u001b[1;31m#             write_summary(loss, \"train/loss\", summary_writer, global_step)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-285-8fb4f275763c>\u001b[0m in \u001b[0;36mtrain_one_batch\u001b[1;34m(self, batch, model, optimizer, parameters)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mparam_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_param_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.LongTensor [5]] is at version 10; expected version 9 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "hidden_dim = 100\n",
    "dropout_ratio = 0.2\n",
    "maxout_pool_size=16\n",
    "max_number_of_iterations = 5\n",
    "with open(r\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\glove_word_embeddings.pkl\", \"rb\") as input_file:\n",
    "    embedding_matrix = pickle.load(input_file)\n",
    "    \n",
    "with autograd.set_detect_anomaly(True):\n",
    "    model = DCN_Model(hidden_dim, embedding_matrix, dropout_ratio, maxout_pool_size, max_number_of_iterations)\n",
    "\n",
    "    # model = model.cpu()\n",
    "    train_model = Train_Model(config, model)\n",
    "\n",
    "    train_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "import torch\n",
    "import random\n",
    "# import nltk\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import copy\n",
    "import os.path\n",
    "import tqdm as tqdm\n",
    "\n",
    "datapath = \"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\\"\n",
    "\n",
    "def find_max_length(data):\n",
    "\n",
    "    \"\"\" Finds the maximum sequence length for data \n",
    "        Args:\n",
    "            data: The data from which sequences will be chosen\n",
    "    \"\"\"\n",
    "    temp = 0\n",
    "    index = 0\n",
    "    for i, _ in enumerate(data):\n",
    "\n",
    "        if (len(data[i]) > temp):\n",
    "            temp = len(data[i])\n",
    "            index = i\n",
    "    return temp,index\n",
    "\n",
    "\n",
    "def pad_data(data):\n",
    "\n",
    "    \"\"\" Pad the data to max_length given\n",
    "        Args: \n",
    "            data: Data that needs to be padded\n",
    "            max_length : The length to be achieved with padding\n",
    "        Returns:\n",
    "            padded_data : Each sequence is padded to make it of length\n",
    "                          max_length.\n",
    "    \"\"\"\n",
    "    padded_data = []\n",
    "    max_length,index =  find_max_length(data)\n",
    "\n",
    "    for lines in tqdm.tqdm(data):\n",
    "        if (len(lines) < max_length):\n",
    "            temp = np.lib.pad(lines, (0,max_length - len(lines)),\n",
    "                'constant', constant_values=0)\n",
    "        else:\n",
    "            temp = lines[:max_length]\n",
    "        padded_data.append(temp)\n",
    "\n",
    "    padded_data = torch.from_numpy(np.array(padded_data)).type(torch.int64)\n",
    "\n",
    "    return padded_data\n",
    "\n",
    "\n",
    "def index_files_using_word_to_index(filename, _dict, max_words):\n",
    "    \n",
    "    f = open(filename, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "    lines = f.readlines()\n",
    "    lines  = [l.lower() for l in lines]\n",
    "    encoded_lines = []\n",
    "    for l in lines:\n",
    "        tokens = l.split()\n",
    "        tokens = tokens[:max_words]\n",
    "        temp = []\n",
    "        for t in tokens:\n",
    "            if t in _dict:\n",
    "                temp.append(_dict[t])\n",
    "            else:\n",
    "                temp.append(1)\n",
    "\n",
    "        encoded_lines.append(temp[:])\n",
    "\n",
    "    return encoded_lines\n",
    "\n",
    "    \n",
    "with open(r\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\dictionaries.pkl\", \"rb\") as input_file:\n",
    "    dictionaries = pickle.load(input_file)\n",
    "word_to_index = dictionaries[\"word_to_index\"]\n",
    "\n",
    "# with open(data_path + \"\\\\\" + \"train\" + \"_word_index.context_pkl.pkl\", \"rb\") as input_file:\n",
    "#     context_word_index = pickle.load(input_file)\n",
    "# with open(data_path + \"\\\\\" + \"train\" + \"_word_index.question_pkl.pkl\", \"rb\") as input_file:\n",
    "#     question_word_index = pickle.load(input_file)\n",
    "    \n",
    "# max_words = 800\n",
    "\n",
    "# # , \".question\"\n",
    "# files = [\".context\"]\n",
    "\n",
    "# for f in files:\n",
    "#     read_path_train = os.path.join(datapath, \"train\" + f)\n",
    "\n",
    "#     read_path_valid = os.path.join(datapath, \"validation\" + f)\n",
    "\n",
    "#     train_file_indexed = index_files_using_word_to_index(read_path_train, word_to_index, max_words)\n",
    "# #     validation_file_indexed = index_files_using_word_to_index(read_path_valid, word_to_index, max_words)\n",
    "#     print(find_max_length(train_file_indexed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 130319/130319 [00:08<00:00, 15545.00it/s]\n"
     ]
    }
   ],
   "source": [
    "a = pad_data(context_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DCN_Model(\n",
       "  (encoder): Word_Level_Encoder(\n",
       "    (embedding): Embedding(106154, 100)\n",
       "    (encoder): LSTM(100, 100, batch_first=True, dropout=0.2)\n",
       "    (dropout_emb): Dropout(p=0.2)\n",
       "  )\n",
       "  (coattention_encoder): Coattention_Encoder(\n",
       "    (question_proj): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (fusion_bilstm): Fusion_BiLSTM(\n",
       "      (fusion_bilstm): LSTM(300, 100, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "      (dropout): Dropout(p=0.2)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2)\n",
       "  )\n",
       "  (decoder): Dynamic_Decoder(\n",
       "    (decoder): LSTM(400, 100, batch_first=True)\n",
       "    (maxout_start): Highway_Maxout_Network(\n",
       "      (r): Linear(in_features=500, out_features=100, bias=False)\n",
       "      (max_out_layer1): Linear(in_features=300, out_features=1600, bias=True)\n",
       "      (max_out_layer2): Linear(in_features=100, out_features=1600, bias=True)\n",
       "      (max_out_layer3): Linear(in_features=200, out_features=16, bias=True)\n",
       "      (loss): CrossEntropyLoss()\n",
       "    )\n",
       "    (maxout_end): Highway_Maxout_Network(\n",
       "      (r): Linear(in_features=500, out_features=100, bias=False)\n",
       "      (max_out_layer1): Linear(in_features=300, out_features=1600, bias=True)\n",
       "      (max_out_layer2): Linear(in_features=100, out_features=1600, bias=True)\n",
       "      (max_out_layer3): Linear(in_features=200, out_features=16, bias=True)\n",
       "      (loss): CrossEntropyLoss()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#             if global_step % config.save_every == 0:\n",
    "#                 logging.info(\"Saving to %s...\" % model_dir)\n",
    "#                 self.save_model(model, optimizer, loss, global_step, epoch, model_dir)\n",
    "\n",
    "#             if global_step % config.eval_every == 0:\n",
    "#                 dev_loss = self.get_dev_loss(model)\n",
    "#                 logging.info(\"Epoch %d, Iter %d, dev loss: %f\" % (epoch, global_step, dev_loss))\n",
    "#                 write_summary(dev_loss, \"dev/loss\", summary_writer, global_step)\n",
    "\n",
    "#                 train_f1, train_em = self.check_f1_em(model, \"train\", num_samples=1000)\n",
    "#                 logging.info(\"Epoch %d, Iter %d, Train F1 score: %f, Train EM score: %f\" % (\n",
    "#                     epoch, global_step, train_f1, train_em))\n",
    "#                 write_summary(train_f1, \"train/F1\", summary_writer, global_step)\n",
    "#                 write_summary(train_em, \"train/EM\", summary_writer, global_step)\n",
    "\n",
    "#                 dev_f1, dev_em = self.check_f1_em(model, \"dev\", num_samples=0)\n",
    "#                 logging.info(\n",
    "#                     \"Epoch %d, Iter %d, Dev F1 score: %f, Dev EM score: %f\" % (epoch, global_step, dev_f1, dev_em))\n",
    "#                 write_summary(dev_f1, \"dev/F1\", summary_writer, global_step)\n",
    "#                 write_summary(dev_em, \"dev/EM\", summary_writer, global_step)\n",
    "\n",
    "#                 if best_dev_f1 is None or dev_f1 > best_dev_f1:\n",
    "#                     best_dev_f1 = dev_f1\n",
    "\n",
    "#                 if best_dev_em is None or dev_em > best_dev_em:\n",
    "#                     best_dev_em = dev_em\n",
    "#                     logging.info(\"Saving to %s...\" % bestmodel_dir)\n",
    "#                     self.save_model(model, optimizer, loss, global_step, epoch, bestmodel_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import tqdm as tqdm\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "\n",
    "class Batch():\n",
    "    \"\"\"A class to hold the information needed for a training batch\"\"\"\n",
    "    def __init__(self,names,context_word_index_batch,question_word_index_batch, span_tensor_batch):\n",
    "        \n",
    "        self.names = names\n",
    "        self.context_word_index_batch = context_word_index_batch\n",
    "#         self.context_word_mask = context_word_mask\n",
    "\n",
    "\n",
    "        self.question_word_index_batch = question_word_index_batch\n",
    "#         self.question_word_mask = question_word_mask\n",
    "        self.span_tensor_batch = span_tensor_batch\n",
    "        self.batch_size = len(self.context_word_index_batch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def refill_batches(batches,batch_size,names, max_context_length, max_question_length,context_word_index,question_word_index,span_tensor):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Adds more batches into the \"batches\" list.\n",
    "    Inputs:\n",
    "      batches: list to add batches to\n",
    "\n",
    "      names: list containing strings of file names [\"train_context\",\"train_question\"] or [\"validation_context\",\"validation_question\"]\n",
    "      data_dir : paths to {train/dev}.{context/question/answer} data files\n",
    "      batch_size: integer ==> how big to make the batches\n",
    "      max_context_length, max_question_length: max length of context and question respectively\n",
    "\n",
    "    \"\"\"\n",
    "    print (\"Refilling batches...\")\n",
    "    tic = time.time()\n",
    "    examples = [] \n",
    "\n",
    "\n",
    "\n",
    "        # add to examples\n",
    "    examples.append((context_word_index, question_word_index, span_tensor))\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    # Make into batches and append to the list batches\n",
    "    for batch_start in xrange(0, len(examples[0][0]), batch_size):\n",
    "\n",
    "        # Note: each of these is a list length batch_size of lists of ints (except on last iter when it might be less than batch_size)\n",
    "        context_word_index_batch = examples[0][0][batch_start:batch_start+batch_size]\n",
    "        question_word_index_batch = examples[0][1][batch_start:batch_start+batch_size]\n",
    "        span_tensor_batch = examples[0][2][batch_start:batch_start+batch_size]\n",
    "\n",
    "        \n",
    "#         print(batch_start)\n",
    "#         print(np.shape(context_word_index_batch))\n",
    "#         print(np.shape(question_word_index_batch))\n",
    "#         print(span_tensor_batch.size())\n",
    "#         print(np.shape(context_word_index_batch))\n",
    "#         print(examples[0][2][batch_start:batch_start+batch_size])\n",
    "        batches.append((context_word_index_batch, question_word_index_batch,span_tensor_batch))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # shuffle the batches\n",
    "    random.shuffle(batches)\n",
    "\n",
    "    toc = time.time()\n",
    "    print (\"Refilling batches took %.2f seconds\" % (toc-tic))\n",
    "    return batches\n",
    "\n",
    "\n",
    "def get_batch_generator(data_dir, names, batch_size, max_context_length, max_question_length):\n",
    "    \"\"\"\n",
    "    This function returns a generator object that yields batches.\n",
    "    The last batch in the dataset will be a partial batch.\n",
    "    Read this to understand generators and the yield keyword in Python: https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do\n",
    "    Inputs:\n",
    "      names: list containing strings of file names = [\"train_context\",\"train_question\"] or [\"validation_context\",\"validation_question\"]\n",
    "      data_dir : paths to {train/dev}.{context/question/answer} data files\n",
    "      batch_size: integer ==> how big to make the batches\n",
    "      max_context_length, max_question_length: max length of context and question respectively\n",
    "\n",
    "    \"\"\"\n",
    "#     word_index_padded =[os.path.join(data_dir + name + \"_word_index_padded.pkl\")  for name in names ]\n",
    "#     with open(word_index_padded[0], \"rb\") as input_file:\n",
    "#         context_word_index_padded = pickle.load(input_file)\n",
    "#     with open(word_index_padded[1], \"rb\") as input_file:\n",
    "#         question_word_index_padded = pickle.load(input_file)\n",
    "\n",
    "    # , \".question\"\n",
    "#     files = [\".context\", \".question\"]\n",
    "\n",
    "#     for f in files:\n",
    "    context_path_train = os.path.join(datapath, \"train.context\")\n",
    "    question_path_train = os.path.join(datapath, \"train.question\")\n",
    "\n",
    "#         read_path_valid = os.path.join(datapath, \"validation\" + f)\n",
    "\n",
    "    context_word_index_old = index_files_using_word_to_index(context_path_train, word_to_index, max_context_length)\n",
    "    question_word_index_old = index_files_using_word_to_index(question_path_train, word_to_index, max_question_length)\n",
    "    \n",
    "#     context_word_index_padded = pad_data(context_word_index)\n",
    "#     question_word_index_padded = pad_data(question_word_index)\n",
    "    \n",
    "#     context_word_index\n",
    "#     validation_file_indexed = index_files_using_word_to_index(read_path_valid, word_to_index, max_words)\n",
    "#     print(find_max_length(train_file_indexed))\n",
    "\n",
    "    with open(data_dir + \"//\" + \"answer_end_pkl.pkl\", \"rb\") as input_file:\n",
    "        answer_end_pkl = pickle.load(input_file)\n",
    "    with open(data_dir + \"//\" + \"answer_start_pkl.pkl\", \"rb\") as input_file:\n",
    "        answer_start_pkl = pickle.load(input_file)\n",
    "\n",
    "#     context_word_index_padded = context_word_index_padded[81509:81512]\n",
    "#     question_word_index_padded = question_word_index_padded[81509:81512]\n",
    "\n",
    "    answer_end = torch.from_numpy(np.array([int(i) for i in answer_end_pkl])).long()\n",
    "    answer_start = torch.from_numpy(np.array([int(i) for i in answer_start_pkl])).long()              \n",
    "    answer_start = torch.unsqueeze(answer_start, 1)\n",
    "    answer_end = torch.unsqueeze(answer_end, 1)\n",
    "\n",
    "    span_tensor_old = torch.cat((answer_start, answer_end), 1)\n",
    "    span_tensor = span_tensor_old[67:83]\n",
    "    context_word_index = context_word_index_old[67:83]\n",
    "    question_word_index = question_word_index_old[67:83]\n",
    "\n",
    "\n",
    "\n",
    "    batches = []\n",
    "    count = 0\n",
    "\n",
    "    while (True):\n",
    "        count = count + 1\n",
    "        if len(batches) == 0: # add more batches\n",
    "            if(count > 2):\n",
    "                break\n",
    "            batches = refill_batches(batches,batch_size,names, max_context_length, max_question_length,context_word_index,question_word_index,span_tensor)\n",
    "        if len(batches) == 0:\n",
    "            break\n",
    "\n",
    "        # Get next batch. These are all lists length batch_size\n",
    "        (context_word_index_batch, question_word_index_batch,span_tensor_batch) = batches.pop(0)\n",
    "        \n",
    "#         print(np.shape(context_word_index_batch))\n",
    "#         print(np.shape(question_word_index_batch))\n",
    "#         print(span_tensor_batch.size())\n",
    "\n",
    "        if(len(context_word_index_batch) == 0):\n",
    "            break\n",
    "            \n",
    "\n",
    "\n",
    "        # Make into a Batch object\n",
    "        batch = Batch(names,context_word_index_batch, question_word_index_batch, span_tensor_batch)\n",
    "\n",
    "        yield batch\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [81500:81519]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import logging\n",
    "import code\n",
    "import pickle\n",
    "import os\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Embedding\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "\n",
    "class DCN_Model(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, embedding_matrix, dropout_ratio, maxout_pool_size, max_number_of_iterations):\n",
    "        super(DCN_Model, self).__init__()\n",
    "\n",
    "        self.encoder = Word_Level_Encoder(hidden_dim, emb_matrix, dropout_ratio)\n",
    "        self.coattention_encoder = Coattention_Encoder(hidden_dim, maxout_pool_size, embedding_matrix, max_number_of_iterations, dropout_ratio)\n",
    "        self.decoder = Dynamic_Decoder(hidden_dim, maxout_pool_size, max_number_of_iterations, dropout_ratio)\n",
    "\n",
    "    def forward(self, context_word_indexes, context_word_mask, question_word_indexes, question_word_mask,span_tensor):\n",
    "        passage_representation = self.encoder.forward(context_word_indexes, context_word_mask)\n",
    "\n",
    "        question_representation = self.encoder.forward(question_word_indexes, question_word_mask)\n",
    "       \n",
    "\n",
    "        U_matrix = self.coattention_encoder.forward(question_representation, passage_representation,context_word_mask)\n",
    "\n",
    "#         print(span_tensor[0].size())\n",
    "\n",
    "        loss, index_start, index_end = self.decoder.forward(U_matrix, context_word_mask, span_tensor)\n",
    "\n",
    "        return loss, index_start, index_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "with open(r\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\glove_word_embeddings.pkl\", \"rb\") as input_file:\n",
    "    emb_matrix = pickle.load(input_file)\n",
    "    \n",
    "names = [\"validation_context\",\"train_context\",\"validation_question\",\"train_question\"]\n",
    "data_dir = \"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\\"\n",
    "\n",
    "# word_index_padded =[os.path.join(data_dir + name + \"_word_index_padded.pkl\")  for name in names ]\n",
    "\n",
    "# with open(word_index_padded[0], \"rb\") as input_file:\n",
    "#     validation_context_word_index_padded = pickle.load(input_file)\n",
    "# with open(word_index_padded[1], \"rb\") as input_file:\n",
    "#     train_context_word_index_padded = pickle.load(input_file)\n",
    "# with open(word_index_padded[2], \"rb\") as input_file:\n",
    "#     validation_question_word_index_padded = pickle.load(input_file)\n",
    "# with open(word_index_padded[3], \"rb\") as input_file:\n",
    "#     train_question_word_index_padded = pickle.load(input_file)\n",
    "    \n",
    "# validation_context_word_mask = (validation_context_word_index_padded != 0).type(torch.int32) \n",
    "# train_context_word_mask = (train_context_word_index_padded != 0).type(torch.int32) \n",
    "# validation_question_word_mask = (validation_question_word_index_padded != 0).type(torch.int32) \n",
    "# train_question_word_mask = (train_question_word_index_padded != 0).type(torch.int32) \n",
    "\n",
    "\n",
    "def get_pretrained_embedding(embedding_matrix):\n",
    "    embedding = nn.Embedding(*embedding_matrix.shape)\n",
    "    embedding.weight = nn.Parameter(torch.from_numpy(embedding_matrix).float())\n",
    "    embedding.weight.requires_grad = False\n",
    "    return embedding\n",
    "\n",
    "\n",
    "# def init_lstm_forget_bias(lstm):\n",
    "#     for names in lstm._all_weights:\n",
    "#         for name in names:\n",
    "#             if name.startswith('bias_'):\n",
    "#                 # set forget bias to 1\n",
    "#                 bias = getattr(lstm, name)\n",
    "#                 n = bias.size(0)\n",
    "#                 start, end = n // 4, n // 2\n",
    "#                 bias.data.fill_(0.)\n",
    "#                 bias.data[start:end].fill_(1.)\n",
    "\n",
    "class Word_Level_Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, embedding_matrix, dropout_ratio):\n",
    "        super(Word_Level_Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = get_pretrained_embedding(embedding_matrix)\n",
    "        self.embedding_dim = self.embedding.embedding_dim\n",
    "\n",
    "        # batch_first = True\n",
    "        # Input: has a dimension of B * m * embedding_dim\n",
    "        # Function parameters: input_size, hidden_size, num_layers_of_LSTM = 1(here)\n",
    "        self.encoder = nn.LSTM(self.embedding_dim, hidden_dim, 1, batch_first=True,\n",
    "                              bidirectional=False, dropout=dropout_ratio) \n",
    "                                     \n",
    "#         init_lstm_forget_bias(self.encoder)\n",
    "        self.dropout_emb = nn.Dropout(p=dropout_ratio)\n",
    "        \n",
    "        # creates a random vector with size= hidden_dim\n",
    "        self.sentinel = nn.Parameter(torch.rand(hidden_dim,))\n",
    "\n",
    "    def forward(self, word_sequence_indexes, word_sequence_mask):\n",
    "#         # stores length of per instance for context/question\n",
    "#         print(\"word_sequence_indexes.size()\")\n",
    "#         print(word_sequence_indexes.size())\n",
    "#         print(\"word_sequence_mask\")\n",
    "#         print(word_sequence_mask.size())\n",
    "        length_per_instance = torch.sum(word_sequence_mask, 1)\n",
    "#         print(length_per_instance)\n",
    "\n",
    "        # returns the word_sequences_embeddings_sorted matrix with the embeddings for each token/word from word_sequence_indexes_sorted\n",
    "        word_sequence_embeddings = self.embedding(word_sequence_indexes)\n",
    "#         print(\"word_sequence_embeddings size\" + str(word_sequence_embeddings.size()))\n",
    "        \n",
    "        # All RNN modules accept packed sequences as inputs.\n",
    "        # Input: word_sequence_embeddings_sorted has a dimension of B x m x l (l is the size of the glove_embedding/ pre-trained embedding/embedding_dim)\n",
    "        packed_word_sequence_embeddings = pack_padded_sequence(word_sequence_embeddings,length_per_instance,batch_first=True,enforce_sorted=False)\n",
    "#         print(\"packed_word_sequence_embeddings\")\n",
    "#         print(packed_word_sequence_embeddings)\n",
    "        # nn.LSTM encoder gets an input of pack_padded_sequence of dimensions: B x m x l (l is the embedding_dim)\n",
    "        # since the input was a packed sequence, the output will also be a packed sequence\n",
    "        output, _ = self.encoder(packed_word_sequence_embeddings)\n",
    "#         print(\"output to lstm \", end = \"\")\n",
    "#         print(output)\n",
    "        \n",
    "        # Pads a packed batch of variable length sequences.\n",
    "        # It is an inverse operation to pack_padded_sequence().\n",
    "        output_to_LSTM_padded, _ = pad_packed_sequence(output, batch_first=True)\n",
    "        \n",
    "        # Returns a contiguous tensor containing the same data as self \n",
    "        output_to_LSTM_padded = output_to_LSTM_padded.contiguous()\n",
    "#         print(\"output_to_LSTM_padded\")\n",
    "#         print(output_to_LSTM_padded.size())\n",
    "        \n",
    "        # dimension:  B x m x l\n",
    "        output_to_LSTM_padded = self.dropout_emb(output_to_LSTM_padded)\n",
    "\n",
    "        # list() creates a list of elements if an iterable is passed\n",
    "        batch_size, _ = list(word_sequence_mask.size())\n",
    "        \n",
    "        \n",
    "        sentinel_matrix = self.sentinel.unsqueeze(0).expand(batch_size, self.hidden_dim).unsqueeze(1).contiguous()  # B x 1 x l\n",
    "        length_per_instance = length_per_instance.unsqueeze(1).expand(batch_size, self.hidden_dim).unsqueeze(1)\n",
    "\n",
    "        # sentinel to be concatenated to the data\n",
    "        sentinel_zero = torch.zeros(batch_size, 1, self.hidden_dim)\n",
    "        \n",
    "        # copy sentinel vector at the end\n",
    "        output_to_LSTM_padded_with_sentinel = torch.cat([output_to_LSTM_padded, sentinel_zero], 1)  # B x (m + 1) x l\n",
    "        \n",
    "        \n",
    "        output_to_LSTM_padded_with_sentinel = output_to_LSTM_padded_with_sentinel.scatter_(1, length_per_instance, sentinel_matrix )\n",
    "\n",
    "        \n",
    "        return output_to_LSTM_padded_with_sentinel\n",
    "    \n",
    "    \n",
    "hidden_dim = 300\n",
    "dropout_ratio = 0.2\n",
    "# encoder = Word_Level_Encoder(hidden_dim, emb_matrix, dropout_ratio)\n",
    "\n",
    "# e = encoder(validation_context_word_index_padded.type(torch.long)[:50],validation_context_word_mask[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class Highway_Maxout_Network(nn.Module):\n",
    "    def __init__(self, hidden_dim, maxout_pool_size, dropout_ratio):\n",
    "        super(Highway_Maxout_Network, self).__init__()\n",
    "        self.hidden_dim = hidden_dim # l\n",
    "        self.maxout_pool_size = maxout_pool_size # p\n",
    "\n",
    "        # Affine mapping from 5l ==> l\n",
    "        self.r = nn.Linear(5 * hidden_dim, hidden_dim, bias=False) \n",
    "       \n",
    "\n",
    "        # Affine mapping from 3*l ==> l*p\n",
    "        self.max_out_layer1 = nn.Linear(3 * hidden_dim, hidden_dim*maxout_pool_size)\n",
    "        \n",
    "        # Affine mapping from l ==> l*p\n",
    "        self.max_out_layer2 = nn.Linear(hidden_dim, hidden_dim*maxout_pool_size)\n",
    "       \n",
    "        # Affine mapping from 2*l ==> p\n",
    "        self.max_out_layer3 = nn.Linear(2 * hidden_dim, maxout_pool_size)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, h_i, U, curr_mask_vector, index_i_minus_1, u_concatenated, mask_matrix, target=None):\n",
    "        batch_size, max_word_length , _ = list(U.size())\n",
    "\n",
    "        # concatenation of ( h_i of dimension = b x l ; u_concatenated of dimension = b x 4l ) along dimension 1 = gives b x 5l\n",
    "        # self.r(b x 5l) ====> b x l (change of vector space)\n",
    "        r = torch.tanh(self.r(torch.cat((h_i.view(-1, self.hidden_dim), u_concatenated), 1)))  # b x 5l => b x l\n",
    "       \n",
    "\n",
    "        # hidden_dim = l\n",
    "        r_expanded = r.unsqueeze(1).expand(batch_size, max_word_length, self.hidden_dim).contiguous()  # b x m x l\n",
    "\n",
    "        m_t1_input = torch.cat((U, r_expanded), 2).view(-1, 3*self.hidden_dim)  # b*m x 3l\n",
    "\n",
    "        m_t1_output = self.max_out_layer1(m_t1_input)  # b*m x p*l\n",
    "        \n",
    "        m_t1_output_resized, _ = m_t1_output.view(-1, self.hidden_dim, self.maxout_pool_size).max(2) # b*m x l\n",
    "\n",
    "        # m_t2_input =  m_t1_output_resized\n",
    "        m_t2_output = self.max_out_layer2(m_t1_output_resized)  # b*m x l*p\n",
    "        \n",
    "        m_t2_output_resized, _ = m_t2_output.view(-1, self.hidden_dim, self.maxout_pool_size).max(2)  # b*m x l\n",
    "\n",
    "        m_t3_input = torch.cat((m_t1_output_resized, m_t2_output_resized), 1)  # b*m x 2l\n",
    "        alpha1 = self.max_out_layer3(m_t3_input)  # b * m x p\n",
    "        alpha2, _ = alpha1.max(1)  # b*m\n",
    "        alpha3 = alpha2.view(-1, max_word_length) # b x m\n",
    "\n",
    "        \n",
    "#         print(alpha3.size())\n",
    "#         print(mask_matrix.size())\n",
    "        alpha3 = alpha3 + mask_matrix  # b x m\n",
    "        \n",
    "        # alpha can be treated as probabilities that assign probability masses todifferent words in context. The word with\n",
    "        # maximum weight(probability) becomes the index(start/end)\n",
    "        alpha4 = F.softmax(alpha3, 1)  # b x m\n",
    "        _, index_i = torch.max(alpha4, dim=1) # b\n",
    "\n",
    "        if curr_mask_vector is None:\n",
    "            curr_mask_vector = (index_i == index_i) # b\n",
    "        else:\n",
    "            index_i = index_i*curr_mask_vector.long()  # b\n",
    "            index_i_minus_1 = index_i_minus_1*curr_mask_vector.long()  # b\n",
    "            curr_mask_vector = (index_i != index_i_minus_1) # b\n",
    "\n",
    "        step_loss = None\n",
    "        \n",
    "        \n",
    "#         input = alpha\n",
    "#         y_actual = target\n",
    "        \n",
    "#         print(alpha4)\n",
    "#         print(target)\n",
    "        target[target < 0] = 0\n",
    "#         print(target)\n",
    "        \n",
    "        \n",
    "        ## loss is only calculated only on that the predicted index at i_th time-step which varies \n",
    "        ## from the predicted index at time-step (i-1)_th time-step\n",
    "        if target is not None:\n",
    "            step_loss = self.loss(alpha4, target)  # b\n",
    "#             print(step_loss)\n",
    "            step_loss1 = step_loss * curr_mask_vector.float() # b\n",
    "\n",
    "        return index_i, curr_mask_vector, step_loss1 # all have dimension: b\n",
    "\n",
    "class Dynamic_Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, maxout_pool_size, max_number_of_iterations, dropout_ratio):\n",
    "        super(Dynamic_Decoder, self).__init__()\n",
    "        self.max_number_of_iterations = max_number_of_iterations\n",
    "        \n",
    "        # batch_first = True\n",
    "        # Input: has a dimension of B * m * embedding_dim\n",
    "        # Function parameters: input_size, hidden_size, num_layers_of_LSTM = 1(here)\n",
    "        self.decoder = nn.LSTM(4 * hidden_dim, hidden_dim, 1, batch_first=True, bidirectional=False)\n",
    "#         init_lstm_forget_bias(self.decoder)\n",
    "\n",
    "        self.maxout_start = Highway_Maxout_Network(hidden_dim, maxout_pool_size, dropout_ratio)\n",
    "        self.maxout_end = Highway_Maxout_Network(hidden_dim, maxout_pool_size, dropout_ratio)\n",
    "\n",
    "    def forward(self, U, document_word_sequence_mask,span_tensor):\n",
    "        batch_size, max_word_length, _ = list(U.size()) # U has dimension : B x m x 2l\n",
    "\n",
    "        curr_mask_start,  curr_mask_end = None, None\n",
    "        results_mask_start, results_start = [], []\n",
    "        results_mask_end, results_end = [], []\n",
    "        step_losses = []\n",
    "        \n",
    "#         print(document_word_sequence_mask.size())\n",
    "\n",
    "        mask_matrix = (1.0 - document_word_sequence_mask.float()) * (-1e30)\n",
    "        indices = torch.arange(0, batch_size, out=torch.LongTensor(batch_size))\n",
    "\n",
    "        # initialize start_zero, end_zero: these are the initial values of start and end indices\n",
    "        # start_i_minus_1 = the first index for the context/question \n",
    "        # end_i_minus_1 = the last index for the context/question \n",
    "        start_i_minus_1 = torch.zeros(batch_size, ).long()\n",
    "        end_i_minus_1 = torch.sum(document_word_sequence_mask, 1) - 1\n",
    "\n",
    "        \n",
    "\n",
    "        # After every iteration the hidden and current state \n",
    "        # at t = length of the sequence (for the one-directional lstm) will\n",
    "        # be returned by the lstm\n",
    "        # the hidden_state_i(h_i) will serve as an input to next lstm\n",
    "        hidden_and_current_state_i = None\n",
    "        start_target = None\n",
    "        end_target = None\n",
    "        \n",
    "        # this sets the start and end target (ie. the y_label) for an answer\n",
    "        \n",
    "        print(\"span tensor : \" ,end = \"\")\n",
    "        print(span_tensor.size())\n",
    "        \n",
    "        if span_tensor is not None:\n",
    "            start_target = span_tensor[:,0]\n",
    "            end_target = span_tensor[:,1]\n",
    "            \n",
    "        # this is just an initialization of u_start\n",
    "        # u_start_i_minus_1 is essentially u_start_zero outside the loop\n",
    "        u_start_i_minus_1 = U[indices, start_i_minus_1, :]  # b x 2l\n",
    "        \n",
    "        # Why do we need an iterative procedure to predict the start and end indices for na answer ? \n",
    "        # Solution: there may exist several intuitive answer spans within the document, each corresponding to a\n",
    "        # local maxima. An iterative technique to select an answer span by alternating between\n",
    "        # predicting the start point and predicting the end point. This iterative procedure allows the model to\n",
    "        # recover from initial local maxima corresponding to incorrect answer spans.\n",
    "        for _ in range(self.max_number_of_iterations):\n",
    "            u_end_i_minus_1 = U[indices, end_i_minus_1, :]  # b x 2l\n",
    "            \n",
    "            # u_concatenated is fed to the lstm\n",
    "            u_concatenated = torch.cat((u_start_i_minus_1, u_end_i_minus_1), 1)  # b x 4l\n",
    "\n",
    "            # the hidden_and_current_state_i = h_i,c_i are essentially hidden and current cell states \n",
    "            # for t = length of the sequence (for the one-directional lstm) after every iteration\n",
    "            lstm_output, hidden_and_current_state_i = self.decoder(u_concatenated.unsqueeze(1), hidden_and_current_state_i)\n",
    "            h_i, c_i = hidden_and_current_state_i\n",
    "\n",
    "            # Inputs to the Highway_Maxout_Network(to find start index) are: hidden_state_i(h_i), start_i_minus_1(index), u_concatenated ==>(u_start_i_minus_1;u_end_i_minus_1) \n",
    "            start_i_minus_1, curr_mask_start, step_loss_start = self.maxout_start(h_i, U, curr_mask_start, start_i_minus_1,\n",
    "                                                                u_concatenated, mask_matrix, start_target)\n",
    "            u_start_i_minus_1 = U[indices, start_i_minus_1, :]  # b x 2l\n",
    "#             print(\"start_i_minus_1\" + str(start_i_minus_1.size()))\n",
    "#             print(\"u_end_i_minus_1\" + str(u_end_i_minus_1.size()))\n",
    "            u_concatenated = torch.cat((u_start_i_minus_1, u_end_i_minus_1), 1)  # b x 4l\n",
    "\n",
    "            # Inputs to the Highway_Maxout_Network(to find end index) are: hidden_state_i(h_i), end_i_minus_1(index), u_concatenated ==>(u_start_i_minus_1;u_end_i_minus_1) \n",
    "            end_i_minus_1, curr_mask_end, step_loss_end = self.maxout_end(h_i, U, curr_mask_end, end_i_minus_1,\n",
    "                                                              u_concatenated, mask_matrix, end_target)\n",
    "\n",
    "            # we minimize the cumulative softmax cross entropy of the start and end points across all iterations.\n",
    "            if span_tensor is not None:\n",
    "                step_loss = step_loss_start + step_loss_end\n",
    "                step_losses.append(step_loss)\n",
    "\n",
    "            \n",
    "            results_mask_start.append(curr_mask_start) # appends all the curr_mask_start ==> dimension: b x num_iterations\n",
    "            results_start.append(start_i_minus_1) # appends all the start_indexes ==> dimension: b x num_iterations\n",
    "            results_mask_end.append(curr_mask_end) # appends all the curr_mask_end ==> dimension: b x num_iterations\n",
    "            results_end.append(end_i_minus_1) # appends all the end_indexes ==> dimension: b x num_iterations\n",
    "\n",
    "        \n",
    "#         print(\"results_mask_start\")\n",
    "#         print(results_mask_start)\n",
    "#         print(\"results_start\")\n",
    "#         print(results_start)\n",
    "        \n",
    "#         print(\"results_mask_end\")\n",
    "#         print(results_mask_end)\n",
    "#         print(\"results_end\")\n",
    "#         print(results_end)\n",
    "        \n",
    "        \n",
    "        result_pos_start1 = torch.sum(torch.stack(results_mask_start, 1), 1).long()\n",
    "#         print(\"start\", end = \"\")\n",
    "#         print(result_pos_start1)\n",
    "        result_pos_start = result_pos_start1 - 1\n",
    "        index_start = torch.gather(torch.stack(results_start, 1), 1, result_pos_start.unsqueeze(1)).squeeze()\n",
    "\n",
    "        result_pos_end1 = torch.sum(torch.stack(results_mask_end, 1), 1).long()\n",
    "#         print(\"start\", end = \"\")\n",
    "#         print(result_pos_end1)\n",
    "        result_pos_end = result_pos_end1 - 1\n",
    "        index_end = torch.gather(torch.stack(results_end, 1), 1, result_pos_end.unsqueeze(1)).squeeze()\n",
    "\n",
    "        loss = None\n",
    "\n",
    "        if span_tensor is not None:\n",
    "            sum_losses = torch.sum(torch.stack(step_losses, 1), 1)\n",
    "            batch_avg_loss = sum_losses / self.max_number_of_iterations\n",
    "            loss = torch.mean(batch_avg_loss)\n",
    "\n",
    "            \n",
    "#         print(loss, index_start, index_end)\n",
    "        return loss, index_start, index_end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "class Coattention_Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, maxout_pool_size, embedding_matrix, max_number_of_iterations, dropout_ratio):\n",
    "        super(Coattention_Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "#         self.encoder = Word_Level_Encoder(hidden_dim, embedding_matrix, dropout_ratio)\n",
    "\n",
    "        ## nn.Linear(input_dim, output_dim)\n",
    "        self.question_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.fusion_bilstm = Fusion_BiLSTM(hidden_dim, dropout_ratio)\n",
    "#         self.decoder = Dynamic_Decoder(hidden_dim, maxout_pool_size, max_number_of_iterations, dropout_ratio)\n",
    "        self.dropout = nn.Dropout(p=dropout_ratio)\n",
    "\n",
    "    def forward(self, question_representation, context_representation,document_word_sequence_mask):\n",
    "        \n",
    "        ############## m = number of instances in document ;  n= number of instances in question ############################33\n",
    "        Q = question_representation # B x (n + 1) x l\n",
    "        D = context_representation  # B x (m + 1) x l\n",
    "        \n",
    "#         print(\"We are in Co-attention Encoder \")\n",
    "        print(\"question_representation.(Output to Encoder Layer) ==  \" + str(Q.size()))\n",
    "        print(\"context_representation. (Output to Encoder Layer)  ==  \" + str(D.size()))\n",
    "\n",
    "        # view function is meant to reshape the tensor.(Similar to reshape function in numpy)\n",
    "        # view( row_size = -1 ,means that number of rows are unknown, column_size)\n",
    "        \n",
    "        \n",
    "        # pass the Q tensor through a non-linearity \n",
    "        Q = torch.tanh(self.question_proj(Q.view(-1, self.hidden_dim))).view(Q.size()) #B x (n + 1) x l\n",
    "\n",
    "        ##################################   Co-Attention starts here  #######################################\n",
    "        \n",
    "        ########################################   Step - 1  ##################################################\n",
    "        # transpose(tensor, first_dimension to be transposed, second_dimension to be transposed)\n",
    "        Q_transpose = torch.transpose(Q, 1, 2) #dimension: B x l x (n + 1)\n",
    "        \n",
    "        # Performs a batch matrix-matrix product of matrices stored in batch1 and batch2.\n",
    "        # batch1 and batch2 must be 3-D tensors each containing the same number of matrices.\n",
    "        L = torch.bmm(D, Q_transpose) # dimension of L : B x (m + 1) x (n + 1)\n",
    "\n",
    "        ####################################### Step-2 ######################################################\n",
    "        A_Q = F.softmax(L, dim=2) # B x (m + 1) x (n + 1)\n",
    "\n",
    "\n",
    "        D_transpose = torch.transpose(D, 1, 2) #dimension: B x l x (m + 1)\n",
    "        C_Q = torch.bmm(D_transpose, A_Q) # (B x l x (m + 1)) x (B x (m + 1) x (n + 1)) => B x l x (n + 1)\n",
    "\n",
    "        ####################################### Step-3 #######################################################\n",
    "        L_tranpose = torch.transpose(L,1,2)\n",
    "        A_D = F.softmax(L_tranpose, dim=2)  # B x (n + 1) x (m + 1)\n",
    "        \n",
    "        \n",
    "        # concatenation along dimension=1:(B x l x (n + 1) ; B x l x (n + 1)  -----> B x 2l x (n + 1) ) x (B x (n + 1) x (m + 1)) ====> B x 2l x (m + 1)\n",
    "        C_D = torch.bmm(torch.cat((Q_transpose, C_Q), 1), A_D) # B x 2l x (m + 1)\n",
    "        C_D_transpose = torch.transpose(C_D, 1, 2)  # B x (m + 1) x 2l\n",
    "\n",
    "        \n",
    "        #######################################  Step-4 ##########################################################\n",
    "        #fusion BiLSTM\n",
    "        # concatenation along dimension = 2:  (B x (m + 1) x 2l ; B x (m + 1) x l  -----> B x (m + 1) x 3l )\n",
    "        bi_lstm_input = torch.cat((C_D_transpose, D), 2) # B x (m + 1) x 3l\n",
    "        bi_lstm_input = self.dropout(bi_lstm_input)\n",
    "        \n",
    "#         print(\"document_word_sequence_mask\")\n",
    "#         print(document_word_sequence_mask.size())\n",
    "       \n",
    "        U = self.fusion_bilstm(bi_lstm_input, document_word_sequence_mask) # B x m x 2l\n",
    "        \n",
    "        print(\"size of U.(U is output of Co-attention encoder) ==  \" + str(U.size()))\n",
    "        \n",
    "        return U\n",
    "\n",
    "#         loss, index_start, index_end = self.decoder(U, document_word_sequence_mask, answer_start, answer_end)\n",
    "#         if answer_start is not None:\n",
    "#             return loss, index_start, index_end\n",
    "#         else:\n",
    "#             return index_start, index_end\n",
    "\n",
    "\n",
    "class Fusion_BiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout_ratio):\n",
    "        super(Fusion_BiLSTM, self).__init__()\n",
    "         # batch_first = True\n",
    "        # Input: has a dimension of B * m * embedding_dim\n",
    "        # Function parameters: input_size, hidden_size, num_layers_of_LSTM = 1(here)\n",
    "        self.fusion_bilstm = nn.LSTM(3 * hidden_dim, hidden_dim, 1, batch_first=True,\n",
    "                                     bidirectional=True, dropout=dropout_ratio)\n",
    "#         init_lstm_forget_bias(self.fusion_bilstm)\n",
    "        self.dropout = nn.Dropout(p=dropout_ratio)\n",
    "\n",
    "    def forward(self, word_sequence_embeddings, word_sequence_mask):\n",
    "        \n",
    "#         print(word_sequence_mask)\n",
    "        # stores length of per instance for context/question\n",
    "        length_per_instance = torch.sum(word_sequence_mask, 1)\n",
    "        \n",
    "        \n",
    "        # sorts the length_per_instance vector in decreasing order\n",
    "        length_per_instance_sorted, length_per_instance_argsort = torch.sort(length_per_instance, 0, True) \n",
    "        \n",
    "        _, length_per_instance_argsort_argsort = torch.sort(length_per_instance_argsort, 0)\n",
    "        \n",
    "        # selects the word indexes from word_sequences_indexes matrix according to of length_per_instance_argsort\n",
    "        word_sequence_embeddings_sorted = torch.index_select(word_sequence_embeddings, 0, length_per_instance_argsort)\n",
    "\n",
    "      \n",
    "        # All RNN modules accept packed sequences as inputs.\n",
    "        # Input: word_sequence_embeddings_sorted has a dimension of B x m x l (l is the size of the glove_embedding/ pre-trained embedding/embedding_dim)\n",
    "        packed_word_sequence_embeddings_sorted = pack_padded_sequence(word_sequence_embeddings_sorted, length_per_instance_sorted, batch_first=True)\n",
    "        \n",
    "        # nn.LSTM encoder gets an input of pack_padded_sequence of dimensions: B x m x l (l is the embedding_dim)\n",
    "        # since the input was a packed sequence, the output will also be a packed sequence\n",
    "        output, _ = self.fusion_bilstm(packed_word_sequence_embeddings_sorted)\n",
    "        \n",
    "        # Pads a packed batch of variable length sequences.\n",
    "        # It is an inverse operation to pack_padded_sequence().\n",
    "        output_to_BiLSTM_padded, _ = pad_packed_sequence(output, batch_first=True)\n",
    "        \n",
    "        # Returns a contiguous tensor containing the same data as self \n",
    "        output_to_BiLSTM_padded = output_to_BiLSTM_padded.contiguous()\n",
    "        \n",
    "        # dimension:  B x m x l\n",
    "        output_to_BiLSTM_padded_sorted = torch.index_select(output_to_BiLSTM_padded, 0, length_per_instance_argsort_argsort)  \n",
    "        output_to_BiLSTM_padded_sorted = self.dropout(output_to_BiLSTM_padded_sorted)\n",
    "\n",
    "        return output_to_BiLSTM_padded_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Config(object):\n",
    "    pass\n",
    "\n",
    "config = Config()\n",
    "config.data_dir = \"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\\"\n",
    "config.word_embedding_size = 100\n",
    "config.hidden_dim = 300\n",
    "config.dropout_ratio = 0.15\n",
    "config.max_context_length = 600\n",
    "config.max_question_length = 30\n",
    "\n",
    "\n",
    "#vector with zeros for unknown words\n",
    "config.num_iterations = 2\n",
    "config.maxout_pool_size=16\n",
    "\n",
    "config.lr = 0.001\n",
    "config.dropout_ratio = 0.15\n",
    "\n",
    "config.max_grad_norm = 5.0\n",
    "config.batch_size = 11\n",
    "config.num_epochs = 2\n",
    "\n",
    "# config.print_every = 100\n",
    "# config.save_every = 50000000\n",
    "# config.eval_every = 1000\n",
    "\n",
    "# config.model_type = 'co-attention'\n",
    "config.reg_lambda = 0.00007\n",
    "config.names = [\"train_context\",\"train_question\"]\n",
    "config.print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\train_word_index.context_pkl.pkl\", \"rb\") as input_file:\n",
    "    train_word_index = pickle.load(input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_index = (np.array(train_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_word_index[81509])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_word_index = np.sort(train_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130319"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((train_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 81510)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_max_length(data):\n",
    "\n",
    "    \"\"\" Finds the maximum sequence length for data \n",
    "        Args:\n",
    "            data: The data from which sequences will be chosen\n",
    "\n",
    "    \"\"\"\n",
    "    temp = 0\n",
    "    index = 0\n",
    "    for i, _ in enumerate(data):\n",
    "\n",
    "        if (len(data[i]) > temp):\n",
    "            temp = len(data[i])\n",
    "            index = i\n",
    "\n",
    "    return temp,index\n",
    "find_max_length(train_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_word_index[81510])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5614, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 0\n",
    "y_actual = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
