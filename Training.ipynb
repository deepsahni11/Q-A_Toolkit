{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import logging\n",
    "import code\n",
    "import gc\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are two ways of letting the model know your intention i.e do you want to train the model or do you want to use the model to evaluate. In case of model.train() the model knows it has to learn the layers and when we use model.eval() it indicates the model that nothing new is to be learnt and the model is used for testing. model.eval() is also necessary because in pytorch if we are using batchnorm and during test if we want to just pass a single image, pytorch throws an error if model.eval() is not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Model:\n",
    "\n",
    "    def __init__(self, config, model):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "        self.parameters_trainable = list(filter(lambda p: p.requires_grad, self.model.parameters()))\n",
    "        self.optimizer = optim.Adam(self.parameters_trainable, lr=self.config.lr)\n",
    "\n",
    "        self.glove_path = os.path.join(config.data_dir, \"glove_word_embeddings.pkl\")\n",
    "        self.num_epochs = config.num_epochs\n",
    "        self.data_dir = config.data_dir\n",
    "        self.names = config.names\n",
    "        self.batch_size = config.batch_size\n",
    "        self.print_every = config.print_every\n",
    "        self.max_context_length = config.max_context_length\n",
    "        self.max_question_length = config.max_question_length\n",
    "\n",
    "    def get_data(self, batch, is_train=True):\n",
    "        \n",
    "        question_word_index_batch = batch.question_word_index_batch\n",
    "\n",
    "        context_word_index_batch = batch.context_word_index_batch\n",
    "        \n",
    "        span_tensor_batch = batch.span_tensor_batch\n",
    "\n",
    "        if is_train:\n",
    "            return context_word_index_batch, question_word_index_batch,span_tensor_batch\n",
    "        else:\n",
    "            return context_word_index_batch, question_word_index_batch\n",
    "      \n",
    "    def get_grad_norm(self, parameters, norm_type=2):\n",
    "        parameters = list(filter(lambda p: p.grad is not None, parameters))\n",
    "        total_norm = 0\n",
    "        for p in parameters:\n",
    "            param_norm = p.grad.data.norm(norm_type)\n",
    "            total_norm += param_norm ** norm_type\n",
    "        total_norm = total_norm ** (1. / norm_type)\n",
    "        return total_norm\n",
    "\n",
    "    def get_param_norm(self, parameters, norm_type=2):\n",
    "        total_norm = 0\n",
    "        for p in parameters:\n",
    "            param_norm = p.data.norm(norm_type)\n",
    "            total_norm += param_norm ** norm_type\n",
    "        total_norm = total_norm ** (1. / norm_type)\n",
    "        return total_norm\n",
    "        \n",
    "    def train_one_batch(self, batch, model, optimizer, parameters):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        context_word_index_batch, question_word_index_batch,  span_tensor_batch = self.get_data(batch)\n",
    "        \n",
    "\n",
    "        \n",
    "        context_word_index_padded_per_batch = pad_data(context_word_index_batch)\n",
    "        question_word_index_padded_per_batch = pad_data(question_word_index_batch)\n",
    "        \n",
    "\n",
    "        context_ids = np.array(context_word_index_padded_per_batch) # shape (batch_size, context_len)\n",
    "        context_mask_per_batch = (context_ids != 0).astype(np.int32) # shape (batch_size, context_len)\n",
    "        context_word_mask_per_batch_new = torch.from_numpy(context_mask_per_batch)\n",
    "\n",
    "        question_ids = np.array(question_word_index_padded_per_batch) # shape (batch_size, context_len)\n",
    "        question_mask_per_batch = (question_ids != 0).astype(np.int32) # shape (batch_size, context_len)\n",
    "        question_word_mask_per_batch_new = torch.from_numpy(question_mask_per_batch)\n",
    "\n",
    "\n",
    "        loss, _, _ = model(context_word_index_padded_per_batch,context_word_mask_per_batch_new, question_word_index_padded_per_batch, question_word_mask_per_batch_new, span_tensor_batch)\n",
    "\n",
    "        l2_reg = None\n",
    "        for W in parameters:\n",
    "            if l2_reg is None:\n",
    "                l2_reg = W.norm(2)\n",
    "            else:\n",
    "                l2_reg = l2_reg + W.norm(2)\n",
    "        loss = loss + config.reg_lambda * l2_reg\n",
    "        \n",
    "        print(loss.grad_fn)\n",
    "        print(loss)\n",
    "\n",
    "#         loss.backward()\n",
    "\n",
    "        param_norm = self.get_param_norm(parameters)\n",
    "        grad_norm = self.get_grad_norm(parameters)\n",
    "        \n",
    "        print(\"param_norm   \" ,end = \"\")\n",
    "        print(param_norm)\n",
    "\n",
    "#         clip_grad_norm_(parameters, config.max_grad_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        return loss.item(), param_norm, grad_norm\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "\n",
    "\n",
    "        model = self.model\n",
    "        parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "        \n",
    "        optimizer = Adam(parameters, lr=config.lr, amsgrad=True)\n",
    "\n",
    "        num_parameters = sum(p.numel() for p in parameters)\n",
    "        logging.info(\"Number of params: %d\" % num_parameters)\n",
    "\n",
    "        exp_loss, best_dev_f1, best_dev_em = None, None, None\n",
    "\n",
    "        epoch = 0\n",
    "        global_step = 0\n",
    "\n",
    "        logging.info(\"Beginning training loop...\")\n",
    "        for epoch in range(1):\n",
    "            epoch_tic = time.time()\n",
    "            for batch in get_batch_generator(self.data_dir, self.names, self.batch_size, self.max_context_length, self.max_question_length):\n",
    "\n",
    "                global_step += 1\n",
    "                iter_tic = time.time()\n",
    "\n",
    "                \n",
    "                loss, param_norm, grad_norm = self.train_one_batch(batch, model, optimizer, parameters)\n",
    "\n",
    "                print(\"loss for batch\" + str(global_step) + \" = \" + str(loss))\n",
    "    \n",
    "                iter_toc = time.time()\n",
    "                iter_time = iter_toc - iter_tic\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            epoch_toc = time.time()\n",
    "            logging.info(\"End of epoch %i. Time for epoch: %f\" % (epoch, epoch_toc - epoch_tic))\n",
    "\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(106154, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refilling batches...\n",
      "Refilling batches took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 2507.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_representation.(Output to Encoder Layer) ==  torch.Size([5, 18, 100])\n",
      "context_representation. (Output to Encoder Layer)  ==  torch.Size([5, 304, 100])\n",
      "size of U.(U is output of Co-attention encoder) ==  torch.Size([5, 303, 200])\n",
      "<AddBackward0 object at 0x0000024071BD4D30>\n",
      "tensor(4.5891, grad_fn=<AddBackward0>)\n",
      "param_norm   tensor(65.6269)\n",
      "loss for batch1 = 4.589073181152344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 2754.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11024.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_representation.(Output to Encoder Layer) ==  torch.Size([11, 21, 100])\n",
      "context_representation. (Output to Encoder Layer)  ==  torch.Size([11, 304, 100])\n",
      "size of U.(U is output of Co-attention encoder) ==  torch.Size([11, 303, 200])\n",
      "<AddBackward0 object at 0x0000024038396B38>\n",
      "tensor(3.6539, grad_fn=<AddBackward0>)\n",
      "param_norm   tensor(65.6269)\n",
      "loss for batch2 = 3.6538546085357666\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 100\n",
    "dropout_ratio = 0.2\n",
    "maxout_pool_size=16\n",
    "max_number_of_iterations = 5\n",
    "with open(r\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\glove_word_embeddings.pkl\", \"rb\") as input_file:\n",
    "    embedding_matrix = pickle.load(input_file)\n",
    "    \n",
    "with autograd.set_detect_anomaly(True):\n",
    "    model = DCN_Model(hidden_dim, embedding_matrix, dropout_ratio, maxout_pool_size, max_number_of_iterations)\n",
    "\n",
    "    # model = model.cpu()\n",
    "    train_model = Train_Model(config, model)\n",
    "\n",
    "    train_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "import torch\n",
    "import random\n",
    "# import nltk\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import copy\n",
    "import os.path\n",
    "import tqdm as tqdm\n",
    "\n",
    "datapath = \"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\\"\n",
    "\n",
    "def find_max_length(data):\n",
    "\n",
    "    \"\"\" Finds the maximum sequence length for data \n",
    "        Args:\n",
    "            data: The data from which sequences will be chosen\n",
    "    \"\"\"\n",
    "    temp = 0\n",
    "    index = 0\n",
    "    for i, _ in enumerate(data):\n",
    "\n",
    "        if (len(data[i]) > temp):\n",
    "            temp = len(data[i])\n",
    "            index = i\n",
    "    return temp,index\n",
    "\n",
    "\n",
    "def pad_data(data):\n",
    "\n",
    "    \"\"\" Pad the data to max_length given\n",
    "        Args: \n",
    "            data: Data that needs to be padded\n",
    "            max_length : The length to be achieved with padding\n",
    "        Returns:\n",
    "            padded_data : Each sequence is padded to make it of length\n",
    "                          max_length.\n",
    "    \"\"\"\n",
    "    padded_data = []\n",
    "    max_length,index =  find_max_length(data)\n",
    "\n",
    "    for lines in tqdm.tqdm(data):\n",
    "        if (len(lines) < max_length):\n",
    "            temp = np.lib.pad(lines, (0,max_length - len(lines)),\n",
    "                'constant', constant_values=0)\n",
    "        else:\n",
    "            temp = lines[:max_length]\n",
    "        padded_data.append(temp)\n",
    "\n",
    "    padded_data = torch.from_numpy(np.array(padded_data)).type(torch.int64)\n",
    "\n",
    "    return padded_data\n",
    "\n",
    "\n",
    "def index_files_using_word_to_index(filename, _dict, max_words):\n",
    "    \n",
    "    f = open(filename, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "    lines = f.readlines()\n",
    "    lines  = [l.lower() for l in lines]\n",
    "    encoded_lines = []\n",
    "    for l in lines:\n",
    "        tokens = l.split()\n",
    "        tokens = tokens[:max_words]\n",
    "        temp = []\n",
    "        for t in tokens:\n",
    "            if t in _dict:\n",
    "                temp.append(_dict[t])\n",
    "            else:\n",
    "                temp.append(1)\n",
    "\n",
    "        encoded_lines.append(temp[:])\n",
    "\n",
    "    return encoded_lines\n",
    "\n",
    "    \n",
    "with open(r\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\dictionaries.pkl\", \"rb\") as input_file:\n",
    "    dictionaries = pickle.load(input_file)\n",
    "word_to_index = dictionaries[\"word_to_index\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import tqdm as tqdm\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "\n",
    "class Batch():\n",
    "    \"\"\"A class to hold the information needed for a training batch\"\"\"\n",
    "    def __init__(self,names,context_word_index_batch,question_word_index_batch, span_tensor_batch):\n",
    "        \n",
    "        self.names = names\n",
    "        self.context_word_index_batch = context_word_index_batch\n",
    "\n",
    "        self.question_word_index_batch = question_word_index_batch\n",
    "        self.span_tensor_batch = span_tensor_batch\n",
    "        self.batch_size = len(self.context_word_index_batch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def refill_batches(batches,batch_size,names, max_context_length, max_question_length,context_word_index,question_word_index,span_tensor):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Adds more batches into the \"batches\" list.\n",
    "    Inputs:\n",
    "      batches: list to add batches to\n",
    "\n",
    "      names: list containing strings of file names [\"train_context\",\"train_question\"] or [\"validation_context\",\"validation_question\"]\n",
    "      data_dir : paths to {train/dev}.{context/question/answer} data files\n",
    "      batch_size: integer ==> how big to make the batches\n",
    "      max_context_length, max_question_length: max length of context and question respectively\n",
    "\n",
    "    \"\"\"\n",
    "    print (\"Refilling batches...\")\n",
    "    tic = time.time()\n",
    "    examples = [] \n",
    "\n",
    "\n",
    "\n",
    "        # add to examples\n",
    "    examples.append((context_word_index, question_word_index, span_tensor))\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    # Make into batches and append to the list batches\n",
    "    for batch_start in xrange(0, len(examples[0][0]), batch_size):\n",
    "\n",
    "        # Note: each of these is a list length batch_size of lists of ints (except on last iter when it might be less than batch_size)\n",
    "        context_word_index_batch = examples[0][0][batch_start:batch_start+batch_size]\n",
    "        question_word_index_batch = examples[0][1][batch_start:batch_start+batch_size]\n",
    "        span_tensor_batch = examples[0][2][batch_start:batch_start+batch_size]\n",
    "\n",
    "        \n",
    "        batches.append((context_word_index_batch, question_word_index_batch,span_tensor_batch))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # shuffle the batches\n",
    "    random.shuffle(batches)\n",
    "\n",
    "    toc = time.time()\n",
    "    print (\"Refilling batches took %.2f seconds\" % (toc-tic))\n",
    "    return batches\n",
    "\n",
    "\n",
    "def get_batch_generator(data_dir, names, batch_size, max_context_length, max_question_length):\n",
    "    \"\"\"\n",
    "    This function returns a generator object that yields batches.\n",
    "    The last batch in the dataset will be a partial batch.\n",
    "    Read this to understand generators and the yield keyword in Python: https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do\n",
    "    Inputs:\n",
    "      names: list containing strings of file names = [\"train_context\",\"train_question\"] or [\"validation_context\",\"validation_question\"]\n",
    "      data_dir : paths to {train/dev}.{context/question/answer} data files\n",
    "      batch_size: integer ==> how big to make the batches\n",
    "      max_context_length, max_question_length: max length of context and question respectively\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    context_path_train = os.path.join(datapath, \"train.context\")\n",
    "    question_path_train = os.path.join(datapath, \"train.question\")\n",
    "\n",
    "\n",
    "    context_word_index_old = index_files_using_word_to_index(context_path_train, word_to_index, max_context_length)\n",
    "    question_word_index_old = index_files_using_word_to_index(question_path_train, word_to_index, max_question_length)\n",
    "    \n",
    "\n",
    "    with open(data_dir + \"//\" + \"answer_end_pkl.pkl\", \"rb\") as input_file:\n",
    "        answer_end_pkl = pickle.load(input_file)\n",
    "    with open(data_dir + \"//\" + \"answer_start_pkl.pkl\", \"rb\") as input_file:\n",
    "        answer_start_pkl = pickle.load(input_file)\n",
    "\n",
    "\n",
    "    answer_end = torch.from_numpy(np.array([int(i) for i in answer_end_pkl])).long()\n",
    "    answer_start = torch.from_numpy(np.array([int(i) for i in answer_start_pkl])).long()              \n",
    "    answer_start = torch.unsqueeze(answer_start, 1)\n",
    "    answer_end = torch.unsqueeze(answer_end, 1)\n",
    "\n",
    "    span_tensor_old = torch.cat((answer_start, answer_end), 1)\n",
    "    span_tensor = span_tensor_old[67:83]\n",
    "    context_word_index = context_word_index_old[67:83]\n",
    "    question_word_index = question_word_index_old[67:83]\n",
    "\n",
    "\n",
    "\n",
    "    batches = []\n",
    "    count = 0\n",
    "\n",
    "    while (True):\n",
    "        count = count + 1\n",
    "        if len(batches) == 0: # add more batches\n",
    "            if(count > 2):\n",
    "                break\n",
    "            batches = refill_batches(batches,batch_size,names, max_context_length, max_question_length,context_word_index,question_word_index,span_tensor)\n",
    "        if len(batches) == 0:\n",
    "            break\n",
    "\n",
    "        # Get next batch. These are all lists length batch_size\n",
    "        (context_word_index_batch, question_word_index_batch,span_tensor_batch) = batches.pop(0)\n",
    "        \n",
    "\n",
    "        if(len(context_word_index_batch) == 0):\n",
    "            break\n",
    "            \n",
    "\n",
    "\n",
    "        # Make into a Batch object\n",
    "        batch = Batch(names,context_word_index_batch, question_word_index_batch, span_tensor_batch)\n",
    "\n",
    "        yield batch\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import logging\n",
    "import code\n",
    "import pickle\n",
    "import os\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Embedding\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "\n",
    "class DCN_Model(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, embedding_matrix, dropout_ratio, maxout_pool_size, max_number_of_iterations):\n",
    "        super(DCN_Model, self).__init__()\n",
    "\n",
    "        self.encoder = Word_Level_Encoder(hidden_dim, emb_matrix, dropout_ratio)\n",
    "        self.coattention_encoder = Coattention_Encoder(hidden_dim, maxout_pool_size, embedding_matrix, max_number_of_iterations, dropout_ratio)\n",
    "        self.decoder = Dynamic_Decoder(hidden_dim, maxout_pool_size, max_number_of_iterations, dropout_ratio)\n",
    "\n",
    "    def forward(self, context_word_indexes, context_word_mask, question_word_indexes, question_word_mask,span_tensor):\n",
    "        passage_representation = self.encoder.forward(context_word_indexes, context_word_mask)\n",
    "\n",
    "        question_representation = self.encoder.forward(question_word_indexes, question_word_mask)\n",
    "       \n",
    "\n",
    "        U_matrix = self.coattention_encoder.forward(question_representation, passage_representation,context_word_mask)\n",
    "\n",
    "        loss, index_start, index_end = self.decoder.forward(U_matrix, context_word_mask, span_tensor)\n",
    "\n",
    "        return loss, index_start, index_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "with open(r\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\glove_word_embeddings.pkl\", \"rb\") as input_file:\n",
    "    emb_matrix = pickle.load(input_file)\n",
    "    \n",
    "names = [\"validation_context\",\"train_context\",\"validation_question\",\"train_question\"]\n",
    "data_dir = \"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\\"\n",
    "\n",
    "\n",
    "\n",
    "def get_pretrained_embedding(embedding_matrix):\n",
    "    embedding = nn.Embedding(*embedding_matrix.shape)\n",
    "    embedding.weight = nn.Parameter(torch.from_numpy(embedding_matrix).float())\n",
    "    embedding.weight.requires_grad = False\n",
    "    return embedding\n",
    "\n",
    "\n",
    "class Word_Level_Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, embedding_matrix, dropout_ratio):\n",
    "        super(Word_Level_Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = get_pretrained_embedding(embedding_matrix)\n",
    "        self.embedding_dim = self.embedding.embedding_dim\n",
    "\n",
    "        # batch_first = True\n",
    "        # Input: has a dimension of B x m x embedding_dim\n",
    "        # Function parameters: input_size, hidden_size, num_layers_of_LSTM = 1(here)\n",
    "        self.encoder = nn.LSTM(self.embedding_dim, self.hidden_dim, 1, batch_first=True,\n",
    "                              bidirectional=False, dropout=dropout_ratio) \n",
    "                                     \n",
    "#         self.dropout_emb = nn.Dropout(p=dropout_ratio)\n",
    "        \n",
    "        # creates a random vector with size= hidden_dim\n",
    "        self.sentinel = nn.Parameter(torch.rand(hidden_dim,))\n",
    "\n",
    "    def forward(self, word_sequence_indexes, word_sequence_mask):\n",
    "        \n",
    "        # stores length of per instance for context/question\n",
    "        # tensor of size = B\n",
    "        length_per_instance = torch.sum(word_sequence_mask, 1)\n",
    "\n",
    "\n",
    "        # returns the word_sequences_embeddings with the embeddings for each token/word from word_sequence_indexes\n",
    "        # word_sequence_embeddings is a tensor of dimension of B x m x l\n",
    "        word_sequence_embeddings = self.embedding(word_sequence_indexes)\n",
    "        \n",
    "        # All RNN modules accept packed sequences as inputs.\n",
    "        # Input: word_sequence_embeddings has a dimension of B x m x l (l is the size of the glove_embedding/ pre-trained embedding/embedding_dim)\n",
    "        packed_word_sequence_embeddings = pack_padded_sequence(word_sequence_embeddings,length_per_instance,batch_first=True,enforce_sorted=False)\n",
    "\n",
    "        \n",
    "        \n",
    "        # nn.LSTM encoder gets an input of pack_padded_sequence of dimensions\n",
    "        # since the input was a packed sequence, the output will also be a packed sequence\n",
    "        output, _ = self.encoder(packed_word_sequence_embeddings)\n",
    "       \n",
    "        \n",
    "        # Pads a packed batch of variable length sequences.\n",
    "        # It is an inverse operation to pack_padded_sequence().\n",
    "        # dimension:  B x m x l\n",
    "        output_to_LSTM_padded, _ = pad_packed_sequence(output, batch_first=True)\n",
    "        \n",
    "        \n",
    "\n",
    "        # list() creates a list of elements if an iterable is passed\n",
    "        # batch_size is a scalar which stores the value of batch size. (batch_size = B)\n",
    "        batch_size, _ = list(word_sequence_mask.size())\n",
    "        \n",
    "        \n",
    "        # dimension of sentinel matrix =  B x 1 x l (replicates or expands along given dimension)\n",
    "        length_per_instance_new_dim = length_per_instance.unsqueeze(1).expand(batch_size, self.hidden_dim).unsqueeze(1)\n",
    "        \n",
    "\n",
    "        # sentinel to be concatenated to the data\n",
    "        # dimension of sentinel_zero =  B x 1 x l\n",
    "        sentinel_zero = torch.zeros(batch_size, 1, self.hidden_dim)\n",
    "        \n",
    "        # copy sentinel vector at the end\n",
    "        # dimension of output_to_LSTM_padded_with_sentinel =  B x (m + 1) x l\n",
    "        output_to_LSTM_padded_with_sentinel = torch.cat([output_to_LSTM_padded, sentinel_zero], 1)  \n",
    "        \n",
    "        \n",
    "        \n",
    "        return output_to_LSTM_padded_with_sentinel\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class Highway_Maxout_Network(nn.Module):\n",
    "    def __init__(self, hidden_dim, maxout_pool_size, dropout_ratio):\n",
    "        super(Highway_Maxout_Network, self).__init__()\n",
    "        self.hidden_dim = hidden_dim # l\n",
    "        self.maxout_pool_size = maxout_pool_size # p\n",
    "\n",
    "        # Affine mapping from 5l ==> l\n",
    "        self.r = nn.Linear(5 * hidden_dim, hidden_dim, bias=False) \n",
    "       \n",
    "\n",
    "        # Affine mapping from 3*l ==> l*p\n",
    "        self.max_out_layer1 = nn.Linear(3 * hidden_dim, hidden_dim*maxout_pool_size)\n",
    "        \n",
    "        # Affine mapping from l ==> l*p\n",
    "        self.max_out_layer2 = nn.Linear(hidden_dim, hidden_dim*maxout_pool_size)\n",
    "       \n",
    "        # Affine mapping from 2*l ==> p\n",
    "        self.max_out_layer3 = nn.Linear(2 * hidden_dim, maxout_pool_size)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, h_i, U, curr_mask_vector, index_i_minus_1, u_concatenated, mask_matrix, target=None):\n",
    "        batch_size, max_word_length , _ = list(U.size())\n",
    "\n",
    "        # concatenation of ( h_i of dimension = b x l ; u_concatenated of dimension = b x 4l ) along dimension 1 = gives b x 5l\n",
    "        # self.r(b x 5l) ====> b x l (change of vector space)\n",
    "        r = torch.tanh(self.r(torch.cat((h_i.view(-1, self.hidden_dim), u_concatenated), 1)))  # b x 5l => b x l\n",
    "       \n",
    "\n",
    "        # hidden_dim = l\n",
    "        r_expanded = r.unsqueeze(1).expand(batch_size, max_word_length, self.hidden_dim).contiguous()  # b x m x l\n",
    "\n",
    "        m_t1_input = torch.cat((U, r_expanded), 2).view(-1, 3*self.hidden_dim)  # b*m x 3l\n",
    "\n",
    "        m_t1_output = self.max_out_layer1(m_t1_input)  # b*m x p*l\n",
    "        \n",
    "        m_t1_output_resized, _ = m_t1_output.view(-1, self.hidden_dim, self.maxout_pool_size).max(2) # b*m x l\n",
    "\n",
    "        # m_t2_input =  m_t1_output_resized\n",
    "        m_t2_output = self.max_out_layer2(m_t1_output_resized)  # b*m x l*p\n",
    "        \n",
    "        m_t2_output_resized, _ = m_t2_output.view(-1, self.hidden_dim, self.maxout_pool_size).max(2)  # b*m x l\n",
    "\n",
    "        m_t3_input = torch.cat((m_t1_output_resized, m_t2_output_resized), 1)  # b*m x 2l\n",
    "        alpha1 = self.max_out_layer3(m_t3_input)  # b * m x p\n",
    "        alpha2, _ = alpha1.max(1)  # b*m\n",
    "        alpha3 = alpha2.view(-1, max_word_length) # b x m\n",
    "\n",
    "        alpha3 = alpha3 + mask_matrix  # b x m\n",
    "        \n",
    "        # alpha can be treated as probabilities that assign probability masses todifferent words in context. The word with\n",
    "        # maximum weight(probability) becomes the index(start/end)\n",
    "        alpha4 = F.softmax(alpha3, 1)  # b x m\n",
    "        _, index_i = torch.max(alpha4, dim=1) # b\n",
    "\n",
    "        if curr_mask_vector is None:\n",
    "            curr_mask_vector = (index_i == index_i) # b\n",
    "        else:\n",
    "            index_i = index_i*curr_mask_vector.long()  # b\n",
    "            index_i_minus_1 = index_i_minus_1*curr_mask_vector.long()  # b\n",
    "            curr_mask_vector = (index_i != index_i_minus_1) # b\n",
    "\n",
    "        step_loss = None\n",
    "        \n",
    "        \n",
    "\n",
    "        target[target < 0] = 0\n",
    "        \n",
    "        \n",
    "        ## loss is only calculated only on that the predicted index at i_th time-step which varies \n",
    "        ## from the predicted index at time-step (i-1)_th time-step\n",
    "        if target is not None:\n",
    "            step_loss = self.loss(alpha4, target)  # b\n",
    "            step_loss1 = step_loss * curr_mask_vector.float() # b\n",
    "\n",
    "        return index_i, curr_mask_vector, step_loss1 # all have dimension: b\n",
    "\n",
    "class Dynamic_Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, maxout_pool_size, max_number_of_iterations, dropout_ratio):\n",
    "        super(Dynamic_Decoder, self).__init__()\n",
    "        self.max_number_of_iterations = max_number_of_iterations\n",
    "        \n",
    "        # batch_first = True\n",
    "        # Input: has a dimension of B * m * embedding_dim\n",
    "        # Function parameters: input_size, hidden_size, num_layers_of_LSTM = 1(here)\n",
    "        self.decoder = nn.LSTM(4 * hidden_dim, hidden_dim, 1, batch_first=True, bidirectional=False)\n",
    "\n",
    "        self.maxout_start = Highway_Maxout_Network(hidden_dim, maxout_pool_size, dropout_ratio)\n",
    "        self.maxout_end = Highway_Maxout_Network(hidden_dim, maxout_pool_size, dropout_ratio)\n",
    "\n",
    "    def forward(self, U, document_word_sequence_mask,span_tensor):\n",
    "        batch_size, max_word_length, _ = list(U.size()) # U has dimension : B x m x 2l\n",
    "\n",
    "        curr_mask_start,  curr_mask_end = None, None\n",
    "        results_mask_start, results_start = [], []\n",
    "        results_mask_end, results_end = [], []\n",
    "        step_losses = []\n",
    "        \n",
    "\n",
    "        # dimension = B x m\n",
    "        mask_matrix = (1.0 - document_word_sequence_mask.float()) * (-1e30)\n",
    "        \n",
    "        # dimension = B\n",
    "        indices = torch.arange(0, batch_size)\n",
    "\n",
    "        \n",
    "        # initialize start_i_minus_1, end_i_minus_1: these are the initial values of start and end indices\n",
    "        # start_i_minus_1 = the first index for the context/question \n",
    "        # end_i_minus_1 = the last index for the context/question \n",
    "        \n",
    "        # dimension = B\n",
    "        start_i_minus_1 = torch.zeros(batch_size).long()\n",
    "        \n",
    "        # dimension = B\n",
    "        end_i_minus_1 = torch.sum(document_word_sequence_mask, 1) - 1\n",
    "\n",
    "        \n",
    "\n",
    "        # After every iteration the hidden and current state \n",
    "        # at t = length of the sequence (for the one-directional lstm) will\n",
    "        # be returned by the lstm\n",
    "        # the hidden_state_i(h_i) will serve as an input to next lstm\n",
    "        hidden_and_current_state_i = None\n",
    "        start_target = None\n",
    "        end_target = None\n",
    "        \n",
    "        # this sets the start and end target (ie. the y_label) for an answer\n",
    "        if span_tensor is not None:\n",
    "            # Dimension = B\n",
    "            start_target = span_tensor[:,0]\n",
    "            \n",
    "            \n",
    "            # Dimension = B\n",
    "            end_target = span_tensor[:,1]\n",
    "            \n",
    "            \n",
    "        # this is just an initialization of u_start\n",
    "        # u_start_i_minus_1 is essentially u_start_zero outside the loop\n",
    "        u_start_i_minus_1 = U[indices, start_i_minus_1, :]  # b x 2l\n",
    "        \n",
    "        # Why do we need an iterative procedure to predict the start and end indices for na answer ? \n",
    "        # Solution: there may exist several intuitive answer spans within the document, each corresponding to a\n",
    "        # local maxima. An iterative technique to select an answer span by alternating between\n",
    "        # predicting the start point and predicting the end point. This iterative procedure allows the model to\n",
    "        # recover from initial local maxima corresponding to incorrect answer spans.\n",
    "        for _ in range(self.max_number_of_iterations):\n",
    "            u_end_i_minus_1 = U[indices, end_i_minus_1, :]  # b x 2l\n",
    "            \n",
    "            # u_concatenated is fed to the lstm\n",
    "            u_concatenated = torch.cat((u_start_i_minus_1, u_end_i_minus_1), 1)  # b x 4l\n",
    "\n",
    "            # the hidden_and_current_state_i = h_i,c_i are essentially hidden and current cell states \n",
    "            # for t = length of the sequence (for the one-directional lstm) after every iteration\n",
    "            lstm_output, hidden_and_current_state_i = self.decoder(u_concatenated.unsqueeze(1), hidden_and_current_state_i)\n",
    "            h_i, c_i = hidden_and_current_state_i\n",
    "\n",
    "            # Inputs to the Highway_Maxout_Network(to find start index) are: hidden_state_i(h_i), start_i_minus_1(index), u_concatenated ==>(u_start_i_minus_1;u_end_i_minus_1) \n",
    "            start_i_minus_1, curr_mask_start, step_loss_start = self.maxout_start(h_i, U, curr_mask_start, start_i_minus_1,\n",
    "                                                                u_concatenated, mask_matrix, start_target)\n",
    "            u_start_i_minus_1 = U[indices, start_i_minus_1, :]  # b x 2l\n",
    "\n",
    "            u_concatenated = torch.cat((u_start_i_minus_1, u_end_i_minus_1), 1)  # b x 4l\n",
    "\n",
    "            # Inputs to the Highway_Maxout_Network(to find end index) are: hidden_state_i(h_i), end_i_minus_1(index), u_concatenated ==>(u_start_i_minus_1;u_end_i_minus_1) \n",
    "            end_i_minus_1, curr_mask_end, step_loss_end = self.maxout_end(h_i, U, curr_mask_end, end_i_minus_1,\n",
    "                                                              u_concatenated, mask_matrix, end_target)\n",
    "\n",
    "            # we minimize the cumulative softmax cross entropy of the start and end points across all iterations.\n",
    "            if span_tensor is not None:\n",
    "                step_loss = step_loss_start + step_loss_end\n",
    "                step_losses.append(step_loss)\n",
    "\n",
    "            \n",
    "            results_mask_start.append(curr_mask_start) # appends all the curr_mask_start ==> dimension: b x num_iterations\n",
    "            results_start.append(start_i_minus_1) # appends all the start_indexes ==> dimension: b x num_iterations\n",
    "            results_mask_end.append(curr_mask_end) # appends all the curr_mask_end ==> dimension: b x num_iterations\n",
    "            results_end.append(end_i_minus_1) # appends all the end_indexes ==> dimension: b x num_iterations\n",
    "\n",
    "        \n",
    "        result_pos_start1 = torch.sum(torch.stack(results_mask_start, 1), 1).long()\n",
    "\n",
    "        result_pos_start = result_pos_start1 - 1\n",
    "        index_start = torch.gather(torch.stack(results_start, 1), 1, result_pos_start.unsqueeze(1)).squeeze()\n",
    "\n",
    "        result_pos_end1 = torch.sum(torch.stack(results_mask_end, 1), 1).long()\n",
    "\n",
    "        result_pos_end = result_pos_end1 - 1\n",
    "        index_end = torch.gather(torch.stack(results_end, 1), 1, result_pos_end.unsqueeze(1)).squeeze()\n",
    "\n",
    "        loss = None\n",
    "\n",
    "        if span_tensor is not None:\n",
    "            sum_losses = torch.sum(torch.stack(step_losses, 1), 1)\n",
    "            batch_avg_loss = sum_losses / self.max_number_of_iterations\n",
    "            loss = torch.mean(batch_avg_loss)\n",
    "\n",
    "            \n",
    "        return loss, index_start, index_end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "class Coattention_Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, maxout_pool_size, embedding_matrix, max_number_of_iterations, dropout_ratio):\n",
    "        super(Coattention_Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        ## nn.Linear(input_dim, output_dim)\n",
    "        # Affine mapping from l ==> l\n",
    "        self.question_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.fusion_bilstm = Fusion_BiLSTM(hidden_dim, dropout_ratio)\n",
    "#         self.dropout = nn.Dropout(p=dropout_ratio)\n",
    "\n",
    "    def forward(self, question_representation, context_representation,document_word_sequence_mask):\n",
    "        \n",
    "        ############## m = max length of instances in one batch of document ;  n= max length of instances in one batch of question ############################33\n",
    "        Q = question_representation # B x (n + 1) x l\n",
    "        D = context_representation  # B x (m + 1) x l\n",
    "        \n",
    "        print(\"question_representation.(Output to Encoder Layer) ==  \" + str(Q.size()))\n",
    "        print(\"context_representation. (Output to Encoder Layer)  ==  \" + str(D.size()))\n",
    "\n",
    "        # view function is meant to reshape the tensor.(Similar to reshape function in numpy)\n",
    "        # view( row_size = -1 ,means that number of rows are unknown, column_size)\n",
    "        # pass the Q tensor through a non-linearity \n",
    "        Q2 = torch.tanh(self.question_proj(Q.view(-1, self.hidden_dim))).view(Q.size()) #B x (n + 1) x l\n",
    "\n",
    "        ##################################   Co-Attention starts here  #######################################\n",
    "        \n",
    "        ########################################   Step - 1  ##################################################\n",
    "        # transpose(tensor, first_dimension to be transposed, second_dimension to be transposed)\n",
    "        Q_transpose = torch.transpose(Q2, 1, 2) #dimension: B x l x (n + 1)\n",
    "        \n",
    "        # Performs a batch matrix-matrix product of matrices stored in batch1 and batch2.\n",
    "        # batch1 and batch2 must be 3-D tensors each containing the same number of matrices.\n",
    "        L = torch.bmm(D, Q_transpose) # dimension of L : B x (m + 1) x (n + 1)\n",
    "\n",
    "        ####################################### Step-2 ######################################################\n",
    "        A_Q = F.softmax(L, dim=2) # B x (m + 1) x (n + 1)\n",
    "\n",
    "\n",
    "        D_transpose = torch.transpose(D, 1, 2) #dimension: B x l x (m + 1)\n",
    "        C_Q = torch.bmm(D_transpose, A_Q) # (B x l x (m + 1)) x (B x (m + 1) x (n + 1)) => B x l x (n + 1)\n",
    "\n",
    "        ####################################### Step-3 #######################################################\n",
    "        L_tranpose = torch.transpose(L,1,2)\n",
    "        A_D = F.softmax(L_tranpose, dim=2)  # B x (n + 1) x (m + 1)\n",
    "        \n",
    "        \n",
    "        # concatenation along dimension=1:(B x l x (n + 1) ; B x l x (n + 1)  -----> B x 2l x (n + 1) ) x (B x (n + 1) x (m + 1)) ====> B x 2l x (m + 1)\n",
    "        C_D = torch.bmm(torch.cat((Q_transpose, C_Q), 1), A_D) # B x 2l x (m + 1)\n",
    "        C_D_transpose = torch.transpose(C_D, 1, 2)  # B x (m + 1) x 2l\n",
    "\n",
    "        \n",
    "        #######################################  Step-4 ##########################################################\n",
    "        #fusion BiLSTM\n",
    "        # concatenation along dimension = 2:  (B x (m + 1) x 2l ; B x (m + 1) x l  -----> B x (m + 1) x 3l )\n",
    "        bi_lstm_input = torch.cat((C_D_transpose, D), 2) # B x (m + 1) x 3l\n",
    "       \n",
    "        U = self.fusion_bilstm(bi_lstm_input, document_word_sequence_mask) # B x m x 2l\n",
    "        \n",
    "        print(\"size of U.(U is output of Co-attention encoder) ==  \" + str(U.size()))\n",
    "        \n",
    "        return U\n",
    "\n",
    "\n",
    "class Fusion_BiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout_ratio):\n",
    "        super(Fusion_BiLSTM, self).__init__()\n",
    "        \n",
    "         # batch_first = True\n",
    "        # Input: has a dimension of B * m * embedding_dim\n",
    "        # Function parameters: input_size, hidden_size, num_layers_of_LSTM = 1(here)\n",
    "        self.fusion_bilstm = nn.LSTM(3 * hidden_dim, hidden_dim, 1, batch_first=True,\n",
    "                                     bidirectional=True, dropout=dropout_ratio)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(p=dropout_ratio)\n",
    "\n",
    "    def forward(self, word_sequence_embeddings, word_sequence_mask):\n",
    "        \n",
    "        # stores length of per instance for context/question\n",
    "        length_per_instance = torch.sum(word_sequence_mask, 1)\n",
    "        \n",
    "      \n",
    "        # All RNN modules accept packed sequences as inputs.\n",
    "        # Input: word_sequence_embeddings has a dimension of B x m+1 x 3l (l is the size of the glove_embedding/ pre-trained embedding/embedding_dim)\n",
    "        packed_word_sequence_embeddings = pack_padded_sequence(word_sequence_embeddings, length_per_instance, batch_first=True,enforce_sorted=False)\n",
    "        \n",
    "        # since the input was a packed sequence, the output will also be a packed sequence\n",
    "        output, _ = self.fusion_bilstm(packed_word_sequence_embeddings)\n",
    "        \n",
    "        # Pads a packed batch of variable length sequences.\n",
    "        # It is an inverse operation to pack_padded_sequence().\n",
    "        # dimension:  B x m x 2l\n",
    "        output_to_BiLSTM_padded, _ = pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "\n",
    "        return output_to_BiLSTM_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Config(object):\n",
    "    pass\n",
    "\n",
    "config = Config()\n",
    "config.data_dir = \"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\\"\n",
    "config.word_embedding_size = 100\n",
    "config.hidden_dim = 300\n",
    "config.dropout_ratio = 0.15\n",
    "config.max_context_length = 600\n",
    "config.max_question_length = 30\n",
    "\n",
    "\n",
    "#vector with zeros for unknown words\n",
    "config.num_iterations = 2\n",
    "config.maxout_pool_size=16\n",
    "\n",
    "config.lr = 0.001\n",
    "config.dropout_ratio = 0.15\n",
    "\n",
    "config.max_grad_norm = 5.0\n",
    "config.batch_size = 11\n",
    "config.num_epochs = 2\n",
    "\n",
    "# config.print_every = 100\n",
    "# config.save_every = 50000000\n",
    "# config.eval_every = 1000\n",
    "\n",
    "# config.model_type = 'co-attention'\n",
    "config.reg_lambda = 0.00007\n",
    "config.names = [\"train_context\",\"train_question\"]\n",
    "config.print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"E:\\\\Internships_19\\\\Internship(Summer_19)\\\\Q&A_Toolkit\\\\Dataset_analysis\\\\SQuAD\\\\train_word_index.context_pkl.pkl\", \"rb\") as input_file:\n",
    "    train_word_index = pickle.load(input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_index = (np.array(train_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_word_index[81509])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_word_index = np.sort(train_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130319"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((train_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 81510)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_max_length(data):\n",
    "\n",
    "    \"\"\" Finds the maximum sequence length for data \n",
    "        Args:\n",
    "            data: The data from which sequences will be chosen\n",
    "\n",
    "    \"\"\"\n",
    "    temp = 0\n",
    "    index = 0\n",
    "    for i, _ in enumerate(data):\n",
    "\n",
    "        if (len(data[i]) > temp):\n",
    "            temp = len(data[i])\n",
    "            index = i\n",
    "\n",
    "    return temp,index\n",
    "find_max_length(train_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_word_index[81510])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5614, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 0\n",
    "y_actual = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
